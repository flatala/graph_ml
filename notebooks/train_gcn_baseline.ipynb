{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0761bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from code_lib.graph_builder import build_emergence_graphs_for_time_range\n",
    "from code_lib.utils import load_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3dc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../elliptic_dataset\"\n",
    "WALLETS_FEATURES = \"wallets_features.csv\"\n",
    "WALLETS_CLASSES = \"wallets_classes.csv\"\n",
    "EDGES_PREFIX = \"AddrTxAddr_edgelist_part_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7afb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(os.path.join(DATA_DIR, WALLETS_FEATURES))\n",
    "node_labels = pd.read_csv(os.path.join(DATA_DIR, WALLETS_CLASSES))\n",
    "edges_with_edge_labels = load_parts(DATA_DIR, EDGES_PREFIX)\n",
    "nodes_with_labels = nodes.merge(node_labels, on='address', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528566a8",
   "metadata": {},
   "source": [
    "### Training a baseline\n",
    "\n",
    "Let's train a simple baseline on a bianry graph with walk length 2 and looking 3 time steps ahead.\n",
    "Let's say we train n time steps 1-37 and evaluate on 40-46 (37 + time horizon, otherwise it's cheating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68f3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique addresses across all time: 822942\n",
      "Total time steps: 49\n",
      "Generating 46 graphs (time steps 1 to 46)...\n",
      "\n",
      "Pre-processing edges by time step...\n",
      "\n",
      "Building graphs...\n",
      "  t=1: nodes= 34853, edges=  66836, labels={np.int64(0): 34853}\n",
      "  t=2: nodes= 24847, edges= 132293, labels={np.int64(0): 24335, np.int64(1): 512}\n",
      "  t=3: nodes= 20137, edges=  64995, labels={np.int64(0): 19896, np.int64(1): 241}\n",
      "  t=4: nodes= 21030, edges=  67269, labels={np.int64(0): 19251, np.int64(1): 1779}\n",
      "  t=5: nodes= 23261, edges=  68436, labels={np.int64(0): 22617, np.int64(1): 644}\n",
      "  t=6: nodes= 11754, edges=  36730, labels={np.int64(0): 11754}\n",
      "  t=7: nodes= 21537, edges=  56077, labels={np.int64(0): 19457, np.int64(1): 2080}\n",
      "  t=8: nodes= 25762, edges=  85857, labels={np.int64(0): 24702, np.int64(1): 1060}\n",
      "  t=9: nodes= 19747, edges=  59974, labels={np.int64(0): 18219, np.int64(1): 1528}\n",
      "  t=10: nodes= 32763, edges=  63503, labels={np.int64(0): 32383, np.int64(1): 380}\n",
      "  t=11: nodes= 21737, edges=  61420, labels={np.int64(0): 21734, np.int64(1): 3}\n",
      "  t=12: nodes= 10076, edges=  25796, labels={np.int64(0): 5827, np.int64(1): 4249}\n",
      "  t=13: nodes= 23708, edges=  49376, labels={np.int64(0): 23701, np.int64(1): 7}\n",
      "  t=14: nodes=  5573, edges=  10656, labels={np.int64(0): 4876, np.int64(1): 697}\n",
      "  t=15: nodes= 14133, edges=  86110, labels={np.int64(0): 13378, np.int64(1): 755}\n",
      "  t=16: nodes=  8097, edges=  17543, labels={np.int64(0): 7901, np.int64(1): 196}\n",
      "  t=17: nodes= 16325, edges=  28034, labels={np.int64(0): 15554, np.int64(1): 771}\n",
      "  t=18: nodes=  5566, edges=  11032, labels={np.int64(0): 4908, np.int64(1): 658}\n",
      "  t=19: nodes= 10076, edges=  17410, labels={np.int64(0): 8074, np.int64(1): 2002}\n",
      "  t=20: nodes= 29451, edges=  75648, labels={np.int64(0): 19946, np.int64(1): 9505}\n",
      "  t=21: nodes= 33764, edges= 147119, labels={np.int64(0): 32581, np.int64(1): 1183}\n",
      "  t=22: nodes= 27413, edges=  69705, labels={np.int64(0): 20521, np.int64(1): 6892}\n",
      "  t=23: nodes= 13587, edges=  24546, labels={np.int64(0): 10302, np.int64(1): 3285}\n",
      "  t=24: nodes= 16651, edges=  29599, labels={np.int64(0): 16529, np.int64(1): 122}\n",
      "  t=25: nodes= 17040, edges=  73732, labels={np.int64(0): 14809, np.int64(1): 2231}\n",
      "  t=26: nodes= 15949, edges=  26861, labels={np.int64(0): 15532, np.int64(1): 417}\n",
      "  t=27: nodes=  8435, edges=  12463, labels={np.int64(0): 8124, np.int64(1): 311}\n",
      "  t=28: nodes=  4940, edges=   9932, labels={np.int64(0): 4413, np.int64(1): 527}\n",
      "  t=29: nodes= 16216, edges=  31522, labels={np.int64(0): 15550, np.int64(1): 666}\n",
      "  t=30: nodes=  9089, edges=  14924, labels={np.int64(0): 8269, np.int64(1): 820}\n",
      "  t=31: nodes= 14726, edges=  27843, labels={np.int64(0): 13827, np.int64(1): 899}\n",
      "  t=32: nodes= 16133, edges=  43591, labels={np.int64(0): 15363, np.int64(1): 770}\n",
      "  t=33: nodes= 13955, edges= 190334, labels={np.int64(0): 12400, np.int64(1): 1555}\n",
      "  t=34: nodes= 12940, edges=  22907, labels={np.int64(0): 12303, np.int64(1): 637}\n",
      "  t=35: nodes= 22655, edges=  49954, labels={np.int64(0): 20165, np.int64(1): 2490}\n",
      "  t=36: nodes= 31764, edges=  75951, labels={np.int64(0): 30946, np.int64(1): 818}\n",
      "  t=37: nodes= 15785, edges=  30221, labels={np.int64(0): 15766, np.int64(1): 19}\n",
      "  t=38: nodes= 16824, edges=  25375, labels={np.int64(0): 15750, np.int64(1): 1074}\n",
      "  t=39: nodes= 11378, edges=  19542, labels={np.int64(0): 9195, np.int64(1): 2183}\n",
      "  t=40: nodes= 26723, edges=  73202, labels={np.int64(0): 23229, np.int64(1): 3494}\n",
      "  t=41: nodes= 22253, edges=  54920, labels={np.int64(0): 19343, np.int64(1): 2910}\n",
      "  t=42: nodes= 32531, edges=  76601, labels={np.int64(0): 32507, np.int64(1): 24}\n",
      "  t=43: nodes= 24600, edges=  99990, labels={np.int64(0): 24289, np.int64(1): 311}\n",
      "  t=44: nodes= 19668, edges=  71159, labels={np.int64(0): 18495, np.int64(1): 1173}\n",
      "  t=45: nodes= 25060, edges= 165778, labels={np.int64(0): 18239, np.int64(1): 6821}\n",
      "  t=46: nodes= 18184, edges=  60362, labels={np.int64(0): 16002, np.int64(1): 2182}\n",
      "\n",
      "Stored 46 graphs\n"
     ]
    }
   ],
   "source": [
    "graphs = build_emergence_graphs_for_time_range(\n",
    "    edges_with_labels_df=edges_with_edge_labels,\n",
    "    nodes_with_classes_df=nodes_with_labels,\n",
    "    first_time_step=1,\n",
    "    last_time_step=49,\n",
    "    max_walk_length=2,\n",
    "    time_horizon=3,\n",
    "    use_distance_labels=False,\n",
    "    keep_class_labels_as_features=False,\n",
    "    ignore_illict=True,\n",
    "    ignore_previously_transacting_with_illicit=True,\n",
    "    cumulative=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"../artifacts/graph_shards\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "graphs_per_shard = 5   # adjust until the resulting files stay under 2 GB\n",
    "for shard_id in range(math.ceil(len(graphs) / graphs_per_shard)):\n",
    "    start = shard_id * graphs_per_shard\n",
    "    end = start + graphs_per_shard\n",
    "    shard_graphs = graphs[start:end]\n",
    "    shard_steps = [int(x.time_step) for x in graphs[start:end]]\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"graphs\": shard_graphs,\n",
    "            \"time_steps\": shard_steps,\n",
    "            \"config\": dict(\n",
    "                max_walk_length=2,\n",
    "                time_horizon=3,\n",
    "                use_distance_labels=False,\n",
    "                keep_class_labels_as_features=False,\n",
    "                ignore_illict=True,\n",
    "                ignore_previously_transacting_with_illicit=True\n",
    "            ),\n",
    "        },\n",
    "        output_dir / f\"emergence_graphs_shard_{shard_id:02}.pt\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afeaa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46 graphs spanning 46 time steps\n"
     ]
    }
   ],
   "source": [
    "shard_dir = Path(\"../artifacts/graph_shards\")\n",
    "shards = sorted(shard_dir.glob(\"emergence_graphs_shard_*.pt\"))\n",
    "\n",
    "graphs = []\n",
    "time_steps = []\n",
    "config = None\n",
    "\n",
    "for shard_path in shards:\n",
    "    payload = torch.load(shard_path, weights_only=False)\n",
    "\n",
    "    if config is None:\n",
    "        config = payload[\"config\"]\n",
    "    else:\n",
    "        if payload[\"config\"] != config:\n",
    "            raise ValueError(f\"Config mismatch in {shard_path}\")\n",
    "\n",
    "    graphs.extend(payload[\"graphs\"])\n",
    "    time_steps.extend(payload[\"time_steps\"])\n",
    "\n",
    "print(f\"Loaded {len(graphs)} graphs spanning {len(time_steps)} time steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4807e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_lib.temporal_graph_builder import convert_to_temporal_snapshots\n",
    "\n",
    "dataset = convert_to_temporal_snapshots(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "225301a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START = 1\n",
    "TRAIN_END = 37\n",
    "EVAL_START = 40\n",
    "EVAL_END = 46\n",
    "\n",
    "train_graphs = [graphs[19], graphs[22], graphs[29], graphs[30]]\n",
    "test_graphs = [graphs[33], graphs[34], graphs[38]] # indexed from 0, so -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c036c4dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d5c1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # First GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        # Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "197111ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"mps\"\n",
    "HIDDEN_DIM = 64\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "num_features = train_graphs[0].x.shape[1]\n",
    "num_classes = 2\n",
    "\n",
    "model = GCN(num_features, HIDDEN_DIM, num_classes).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b35bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, graphs, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "    \n",
    "    for graph in graphs:\n",
    "        graph = graph.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "        loss = F.cross_entropy(out, graph.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred == graph.y).sum().item()\n",
    "        \n",
    "        total_loss += loss.item() * graph.num_nodes\n",
    "        total_correct += correct\n",
    "        total_nodes += graph.num_nodes\n",
    "    \n",
    "    avg_loss = total_loss / total_nodes\n",
    "    avg_acc = total_correct / total_nodes\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c4368c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graphs):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for graph in graphs:\n",
    "            graph = graph.to(DEVICE)\n",
    "            out = model(graph.x, graph.edge_index)\n",
    "            probs = F.softmax(out, dim=1)\n",
    "            preds = out.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(graph.y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e51cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  10 | Train Loss: 4.9451 | Train Acc: 0.8655 | Eval Acc: 0.9075: 100%|██████████| 10/10 [02:22<00:00, 14.21s/it]   \n"
     ]
    }
   ],
   "source": [
    "train_loop = tqdm(range(1, NUM_EPOCHS + 1))\n",
    "for epoch in train_loop:\n",
    "    train_loss, train_acc = train_epoch(model, train_graphs, optimizer)\n",
    "\n",
    "    text = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\"\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        # Evaluate on eval set periodically\n",
    "        eval_preds, eval_labels, eval_probs = evaluate(model, test_graphs)\n",
    "        eval_acc = (eval_preds == eval_labels).mean()\n",
    "        \n",
    "        text = f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Eval Acc: {eval_acc:.4f}\"\n",
    "\n",
    "    train_loop.set_description(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3733f05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciszeklatala/mamba/envs/graph-ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/franciszeklatala/mamba/envs/graph-ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/franciszeklatala/mamba/envs/graph-ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Emergence       0.91      1.00      0.95   1546413\n",
      "   Emergence       0.00      0.00      0.00    157638\n",
      "\n",
      "    accuracy                           0.91   1704051\n",
      "   macro avg       0.45      0.50      0.48   1704051\n",
      "weighted avg       0.82      0.91      0.86   1704051\n",
      "\n",
      "ROC-AUC: 0.5000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1546413       0]\n",
      " [ 157638       0]]\n",
      "\n",
      "--- Per-Timestep Evaluation ---\n",
      "t=40: Acc=0.8931 | Positives: 0/56751 | Total: 530840\n",
      "t=41: Acc=0.9139 | Positives: 0/47552 | Total: 552376\n",
      "t=42: Acc=0.9141 | Positives: 0/53335 | Total: 620835\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n--- Training Set ---\")\n",
    "# train_preds, train_labels, train_probs = evaluate(model, train_graphs)\n",
    "# print(classification_report(train_labels, train_preds, target_names=['No Emergence', 'Emergence']))\n",
    "# if len(np.unique(train_labels)) == 2:\n",
    "#     auc = roc_auc_score(train_labels, train_probs[:, 1])\n",
    "#     print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "print(\"\\n--- Evaluation Set ---\")\n",
    "eval_preds, eval_labels, eval_probs = evaluate(model, test_graphs)\n",
    "print(classification_report(eval_labels, eval_preds, target_names=['No Emergence', 'Emergence']))\n",
    "if len(np.unique(eval_labels)) == 2:\n",
    "    auc = roc_auc_score(eval_labels, eval_probs[:, 1])\n",
    "    print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(eval_labels, eval_preds))\n",
    "\n",
    "print(\"\\n--- Per-Timestep Evaluation ---\")\n",
    "for i, graph in enumerate(test_graphs):\n",
    "    graph = graph.to(DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        labels = graph.y.cpu().numpy()\n",
    "        \n",
    "        acc = (preds == labels).mean()\n",
    "        pos_count = (labels == 1).sum()\n",
    "        pos_correct = ((preds == 1) & (labels == 1)).sum()\n",
    "        \n",
    "        print(f\"t={EVAL_START + i}: Acc={acc:.4f} | Positives: {pos_correct}/{pos_count} | Total: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900a1e0",
   "metadata": {},
   "source": [
    "So yeah the signal is too sprase and model predicts that no nodes will have illicit emergence. Maybe a long walk length distance reward would yield better gradients, but then we need to speed up computation to even build such a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
