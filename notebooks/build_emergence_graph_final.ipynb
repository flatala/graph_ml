{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0add380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../elliptic_dataset\"\n",
    "WALLETS_FEATURES = \"wallets_features.csv\"\n",
    "WALLETS_CLASSES = \"wallets_classes.csv\"\n",
    "EDGES_PREFIX = \"AddrTxAddr_edgelist_part_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ff6b3",
   "metadata": {},
   "source": [
    "#### 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parts(data_dir: str, base: str) -> pd.DataFrame:\n",
    "    paths = glob.glob(os.path.join(data_dir, f\"{base}*.csv\"))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files found for pattern {base}_part_*.csv in {data_dir}\")\n",
    "\n",
    "    paths.sort(key=lambda p: int(re.search(r'_part_(\\d+)\\.csv$', p).group(1)))\n",
    "    return pd.concat((pd.read_csv(p) for p in paths), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(os.path.join(DATA_DIR, WALLETS_FEATURES))\n",
    "node_labels = pd.read_csv(os.path.join(DATA_DIR, WALLETS_CLASSES))\n",
    "edges_with_edge_labels = load_parts(DATA_DIR, EDGES_PREFIX)\n",
    "nodes_with_labels = nodes.merge(node_labels, on='address', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0307a",
   "metadata": {},
   "source": [
    "#### 2. Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = sorted(nodes['Time step'].unique())\n",
    "\n",
    "all_addresses = nodes['address'].unique()\n",
    "num_nodes_total = len(all_addresses)\n",
    "\n",
    "# index all addresses from 0 to N (num_nodes_total)\n",
    "address_to_id = {addr: idx for idx, addr in enumerate(all_addresses)}\n",
    "\n",
    "print(f\"Total unique addresses across all time: {num_nodes_total}\")\n",
    "print(f\"Total time steps: {len(time_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dba9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_features(nodes_up_to_t, active_addresses, address_to_local_id, keep_class_labels_as_features: bool = True):\n",
    "    \"\"\"\n",
    "    Extract latest features for each active node (OPTIMIZED VERSION).\n",
    "    When a node appears multiple times, use the most recent feature values.\n",
    "    \n",
    "    Args:\n",
    "        nodes_up_to_t: DataFrame with node data up to current time step\n",
    "        active_addresses: array/list of addresses active (have emerged) up to current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: node features [num_nodes, num_features]\n",
    "    \"\"\"\n",
    "\n",
    "    # include labels at t as features (exploiting the knowledge, may be bad for \"unobvious\" emergence)\n",
    "    if keep_class_labels_as_features:\n",
    "        feature_cols = [col for col in nodes_up_to_t.columns \n",
    "                    if col not in ['address', 'Time step']]\n",
    "\n",
    "    # don't include labels at t as features (less bias towards emergence nera illict nodes)\n",
    "    else:    \n",
    "        feature_cols = [col for col in nodes_up_to_t.columns\n",
    "                    if col not in ['address', 'Time step', 'class']]\n",
    "    \n",
    "    # we sort by time to only include latest node features\n",
    "    nodes_sorted = nodes_up_to_t.sort_values('Time step', descending=False)\n",
    "\n",
    "    # use groupby to get latest row per address\n",
    "    latest_per_address = nodes_sorted.groupby('address', as_index=True)[feature_cols].last()\n",
    "    \n",
    "    # prepare an empty array\n",
    "    num_features = len(feature_cols)\n",
    "    num_active_nodes = len(active_addresses)\n",
    "    node_features = np.zeros((num_active_nodes, num_features))\n",
    "    \n",
    "    # populate features\n",
    "    for addr in active_addresses:\n",
    "        if addr in latest_per_address.index:\n",
    "            local_id = address_to_local_id[addr]\n",
    "            node_features[local_id] = latest_per_address.loc[addr].values\n",
    "    \n",
    "    return torch.tensor(node_features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edge_index(edges_up_to_t, address_id_map_until_t):\n",
    "    \"\"\"\n",
    "    Build edge index including ALL edges\n",
    "    \n",
    "    Args:\n",
    "        edges_up_to_t: DataFrame with edge data up to current time step\n",
    "        address_id_map_until_t: dict mapping address that have emerged until time t (t included) -> local node ID\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: edge_index [2, num_edges]\n",
    "    \"\"\"\n",
    "\n",
    "    # filter edges where both endpoints exist (maybe unnecessary)\n",
    "    valid_src = edges_up_to_t['input_address'].isin(address_to_local_id.keys())\n",
    "    valid_dst = edges_up_to_t['output_address'].isin(address_to_local_id.keys())\n",
    "    edges_valid = edges_up_to_t[valid_src & valid_dst]\n",
    "    \n",
    "    if len(edges_valid) == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "    \n",
    "    # map addresses to local IDs\n",
    "    src_ids = edges_valid['input_address'].map(address_to_local_id).values\n",
    "    dst_ids = edges_valid['output_address'].map(address_to_local_id).values\n",
    "    \n",
    "    # stack into edge_index\n",
    "    edge_index = np.stack([src_ids, dst_ids], axis=0)\n",
    "    \n",
    "    return torch.tensor(edge_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def build_undirected_adjacency_matrix(edge_index: torch.Tensor, num_nodes: int) -> scipy.sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Build symmetric sparse adjacency matrix from edge_index.\n",
    "    \n",
    "    Args:\n",
    "        edge_index: torch.Tensor [2, num_edges], directed edge list\n",
    "        num_nodes: int, total number of nodes in the graph \n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: symmetric adjacency matrix [num_nodes, num_nodes]\n",
    "    \"\"\"\n",
    "    if edge_index.shape[1] == 0:\n",
    "        return csr_matrix((num_nodes, num_nodes))\n",
    "    \n",
    "    # convert to numpy\n",
    "    edge_index_np = edge_index.cpu().numpy()\n",
    "    \n",
    "    # create directed edges\n",
    "    src = edge_index_np[0]\n",
    "    dst = edge_index_np[1]\n",
    "    \n",
    "    # add reverse edges for undirected graph \n",
    "    all_src = np.concatenate([src, dst])\n",
    "    all_dst = np.concatenate([dst, src])\n",
    "    \n",
    "    # create sparse matrix (values are 1s for adjacency)\n",
    "    data = np.ones(len(all_src), dtype=np.float32)\n",
    "    adjacency_matrix = csr_matrix((data, (all_src, all_dst)), shape=(num_nodes, num_nodes))\n",
    "    \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e814cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reachability_matrix(adjacency_matrix, max_walk_length):\n",
    "    \"\"\"\n",
    "    Compute k-hop reachability matrix using sparse matrix powers.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: scipy.sparse.csr_matrix, adjacency matrix\n",
    "        walk_length: int, maximum walk length to reach the neighbours \n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: boolean matrix where [i,j]=1 if j is reachable from i in ≤k hops\n",
    "    \"\"\"\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # start with identity (0-hop: each node reaches itself)\n",
    "    reachability = sp.eye(num_nodes, format='csr')\n",
    "    \n",
    "    # current power of adjacency matrix\n",
    "    current_power = adjacency_matrix.copy()\n",
    "    \n",
    "    # add A + A^2 + ... + A^k\n",
    "    # this will give us positive (i,j) values whenever we can reach node j from i in a k-hop walk\n",
    "    for hop in range(1, max_walk_length + 1):\n",
    "        if hop > 1:\n",
    "            current_power = current_power @ adjacency_matrix\n",
    "        reachability = reachability + current_power\n",
    "    \n",
    "    # convert to boolean matrix - positive value means coulkd be reached\n",
    "    reachability = (reachability > 0).astype(np.float32)\n",
    "    \n",
    "    return reachability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: i think returning zeros whenever we cannt reach and its not the same zero is kinda stupi. Inf would be better?\n",
    "\n",
    "def compute_distance_matrix(adjacency_matrix, max_walk_length) -> scipy.sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Compute a distance matrix from any node in the graph to any other node.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: scipy.sparse.csr_matrix, adjacency matrix\n",
    "        k_hops: int, neighborhood radius\n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: boolean matrix where [i,j]=1 if j is reachable from i in ≤k hops\n",
    "    \"\"\"\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # start with identity (0-hop: each node reaches itself)\n",
    "    visited = sp.eye(num_nodes, format='csr')\n",
    "    distances = sp.csr_matrix((num_nodes, num_nodes))\n",
    "    \n",
    "    # current power of adjacency matrix\n",
    "    current_power = adjacency_matrix.copy()\n",
    "    \n",
    "    # add A + A^2 + ... + A^k\n",
    "    # this will give us edges whenever we can reach the other matrix in a k-hop walk\n",
    "    for hop in range(1, max_walk_length + 1):\n",
    "        if hop > 1:\n",
    "            current_power = current_power @ adjacency_matrix\n",
    "\n",
    "        # only keep the values for non-visited nodes\n",
    "        reached_for_first_time = current_power - current_power.multiply(visited)\n",
    "\n",
    "        # set distance matrix values to hop\n",
    "        mask = reached_for_first_time.sign() * hop\n",
    "\n",
    "        # update visited matrix\n",
    "        visited = (visited + current_power).minimum(1)\n",
    "\n",
    "        # update distances\n",
    "        distances = distances + mask\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(\n",
    "    current_time_step: int, \n",
    "    edges_df: pd.DataFrame,\n",
    "    active_addresses: set,\n",
    "    active_address_to_local_id,\n",
    "    all_illicit_addresses: set,\n",
    "    edge_index_at_t: torch.Tensor, \n",
    "    use_distance_labels: bool = True,\n",
    "    max_walk_length: int = 2,\n",
    "    time_horizon: int = 3,\n",
    "    ignore_illict: bool = True,\n",
    "    ignore_previously_transacting_with_illicit: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate labels for illicit activity emergence prediction in a temporal transaction graph.\n",
    "    \n",
    "    This function predicts which nodes are at risk of exposure to NEW illicit activity by \n",
    "    computing either distance-based or binary labels. \"NEW\" illicit nodes are those that \n",
    "    don't exist at the current time step but emerge in the future time horizon.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int\n",
    "            Current time step t for which to generate labels\n",
    "        edges_df: pd.DataFrame\n",
    "            DataFrame containing all transaction edges with columns:\n",
    "            - 'Time step': temporal information\n",
    "            - 'input_address': source node address\n",
    "            - 'output_address': destination node address\n",
    "        active_addresses: set\n",
    "            Set of all addresses that have emerged (are active) up to and including time t\n",
    "        active_address_to_local_id: dict\n",
    "            Mapping from active addresses to local node IDs (0 to num_nodes-1)\n",
    "        all_illicit_addresses: set\n",
    "            Set of ALL illicit addresses in the entire graph (across all time steps)\n",
    "        edge_index_at_t: torch.Tensor\n",
    "            Edge index tensor [2, num_edges] representing the graph structure at time t\n",
    "        use_distance_labels: bool, default=True\n",
    "            If True, labels are distances (0, 1, 2, ..., max_walk_length+1)\n",
    "            If False, labels are binary (0 or 1)\n",
    "        max_walk_length: int, default=2\n",
    "            Maximum number of hops to consider in the neighborhood radius\n",
    "        time_horizon: int, default=3\n",
    "            Number of future time steps to look ahead (t+1, t+2, ..., t+time_horizon)\n",
    "        ignore_illict: bool, default=True\n",
    "            If True, nodes that are already illicit at time t receive default labels\n",
    "            (max_walk_length+1 for distance, 0 for binary) and illicit nodes are excluded\n",
    "            from the set of future illicit transactors\n",
    "        ignore_previously_transacting_with_illicit: bool, default=True\n",
    "            If True, nodes that have any transaction history with illicit nodes up to time t\n",
    "            receive default labels and are excluded from the set of future illicit transactors\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: labels [num_nodes] with dtype=torch.long\n",
    "        \n",
    "        If use_distance_labels=True:\n",
    "            - 0: node will directly transact with NEW illicit nodes\n",
    "            - 1, 2, ..., max_walk_length: distance to nearest neighbor that will transact with NEW illicit\n",
    "            - max_walk_length + 1: no NEW illicit activity in k-hop neighborhood (default/no emergence)\n",
    "        \n",
    "        If use_distance_labels=False:\n",
    "            - 0: no NEW illicit activity in k-hop neighborhood (default)\n",
    "            - 1: at least one node in k-hop neighborhood will transact with NEW illicit nodes\n",
    "    \n",
    "    Algorithm:\n",
    "        1. Identify \"future illicit\" addresses: illicit nodes that don't exist at time t\n",
    "        2. Find all addresses that will transact with future illicit in [t+1, ..., t+time_horizon]\n",
    "        3. Apply filters based on ignore_illict and ignore_previously_transacting_with_illicit\n",
    "        4. Build adjacency matrix and compute distances or reachability\n",
    "        5. For each node, compute label based on proximity to future illicit transactors\n",
    "    \"\"\"\n",
    "\n",
    "    # get the number of nodes in the graph at time t\n",
    "    num_nodes = len(active_addresses)\n",
    "\n",
    "    # prepare reverse mapping for looking up addresses\n",
    "    id_to_address = {idx: addr for addr, idx in active_address_to_local_id.items()}\n",
    "\n",
    "    # build the adjacency matrix\n",
    "    adjacency_matrix = build_undirected_adjacency_matrix(edge_index_at_t, num_nodes)\n",
    "    \n",
    "    # Find illicit addresses that already exist at time t - we want\n",
    "    # to exclude these, since we care about predicting emergence, not \n",
    "    # if a neighbour will have any edge with any illicit in the future\n",
    "    existing_illicit_at_t = active_addresses & all_illicit_addresses\n",
    "    \n",
    "    # illicit nodes that don't exist at time t yet\n",
    "    future_illicit_addresses = all_illicit_addresses - existing_illicit_at_t\n",
    "    \n",
    "    # collect all nodes that will in future transact with \n",
    "    # illicit nodes that don't yet exist in the graph\n",
    "    future_illicit_transactor_adresses = set()\n",
    "    for future_t in range(current_time_step + 1, current_time_step + time_horizon + 1):\n",
    "        # select future transactions\n",
    "        edges_future = edges_df[edges_df['Time step'] == future_t]\n",
    "\n",
    "        # continue if none are foud in the timestep\n",
    "        if edges_future.empty:\n",
    "            continue\n",
    "        \n",
    "        # find transaction edges that go to new illicit adresses\n",
    "        illicit_dst_mask = edges_future['output_address'].isin(future_illicit_addresses)\n",
    "        src_to_illicit = set(edges_future.loc[illicit_dst_mask, 'input_address'].values)\n",
    "        \n",
    "        # find transaction edges that come from new illicit adresses\n",
    "        illicit_src_mask = edges_future['input_address'].isin(future_illicit_addresses)\n",
    "        dst_from_illicit = set(edges_future.loc[illicit_src_mask, 'output_address'].values)\n",
    "        \n",
    "        # collect all the adresses\n",
    "        future_illicit_transactor_adresses.update(src_to_illicit | dst_from_illicit)\n",
    "\n",
    "    # if it is specified so, ignore the transactors that are illict themselves\n",
    "    # (it might be more interesting to look for illicit emergence where tehre is no illicit nodes)\n",
    "    if ignore_illict:\n",
    "        future_illicit_transactor_adresses = future_illicit_transactor_adresses - all_illicit_addresses\n",
    "    \n",
    "    # if it is specified so, also ignore nodes that have\n",
    "    # previously transacted with illicit nodes\n",
    "    nodes_with_illicit_history = set()\n",
    "    if ignore_previously_transacting_with_illicit:\n",
    "        # get all edges up to current time\n",
    "        edges_up_to_t = edges_df[edges_df['Time step'] <= current_time_step]\n",
    "        \n",
    "        # check for edges to illicit addresses\n",
    "        to_illicit_mask = edges_up_to_t['output_address'].isin(all_illicit_addresses)\n",
    "        src_to_illicit = set(edges_up_to_t.loc[to_illicit_mask, 'input_address'].values)\n",
    "        \n",
    "        # check for edges from illicit adresses\n",
    "        from_illicit_mask = edges_up_to_t['input_address'].isin(all_illicit_addresses)\n",
    "        dst_from_illicit = set(edges_up_to_t.loc[from_illicit_mask, 'output_address'].values)\n",
    "        \n",
    "        # combine both\n",
    "        nodes_with_illicit_history = src_to_illicit | dst_from_illicit\n",
    "        \n",
    "        # remove these from future_illicit_transactor_adresses\n",
    "        future_illicit_transactor_adresses = future_illicit_transactor_adresses - nodes_with_illicit_history\n",
    "\n",
    "    # map adresses to ids for the nodes that are emerged at t\n",
    "    # and will transact with future illict nodes in horizon\n",
    "    future_illicit_transactor_ids = []\n",
    "    for addr in future_illicit_transactor_adresses:\n",
    "        if addr in active_address_to_local_id:\n",
    "            future_illicit_transactor_ids.append(active_address_to_local_id[addr])\n",
    "\n",
    "    # convert to numpy array\n",
    "    future_illicit_transactor_ids = np.array(future_illicit_transactor_ids)\n",
    "    \n",
    "    # if we want labels to be the distance to the node's \n",
    "    # nearest neighbour (within the walk_length) that \n",
    "    # will make transactions with future illicit nodes\n",
    "    if use_distance_labels:\n",
    "        # compute distances to neighbours within k-hops\n",
    "        distances = compute_distance_matrix(adjacency_matrix, max_walk_length)\n",
    "\n",
    "        # Initialize all labels to walk_length + 1 (default case)\n",
    "        # TODO: readdress this, for now walk_length + 1 means none\n",
    "        labels = np.full(num_nodes, max_walk_length + 1, dtype=int)\n",
    "\n",
    "        # if no nodes emerged at t will transact with future illicit, return\n",
    "        if len(future_illicit_transactor_adresses) == 0:\n",
    "            return torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # only keep columns corresponding to emerged nodes\n",
    "        # that will transact with future illicit nodes\n",
    "        distances_to_new_illicit = distances[:, future_illicit_transactor_ids].toarray()\n",
    "\n",
    "        # Create set for fast lookup\n",
    "        future_illicit_transactor_set = set(future_illicit_transactor_ids)\n",
    "\n",
    "        # Compute labels for each node\n",
    "        for i in range(num_nodes):\n",
    "            node_address = id_to_address[i]\n",
    "\n",
    "            # if it is specified to not label illicit nodes\n",
    "            if ignore_illict and node_address in all_illicit_addresses:\n",
    "                continue\n",
    "\n",
    "            # if we also dont want to label nodes with illicit transaction history\n",
    "            elif ignore_previously_transacting_with_illicit and node_address in nodes_with_illicit_history:\n",
    "                continue\n",
    "\n",
    "            elif i in future_illicit_transactor_set:\n",
    "                # this node itself will transact with new illicit\n",
    "                labels[i] = 0\n",
    "                \n",
    "            else:\n",
    "                # otherwise find minimum non-zero distance\n",
    "                row_distances = distances_to_new_illicit[i, :]\n",
    "                valid_distances = row_distances[row_distances > 0]\n",
    "                if len(valid_distances) > 0:\n",
    "                    labels[i] = int(valid_distances.min())\n",
    "                # NOTE: if not found: stays at walk_length + 1 \n",
    "                # (no new illicit in k-hop neighborhood)\n",
    "\n",
    "        return torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # in the case it is specified to only use thebinary labels\n",
    "    else:\n",
    "        labels = torch.zeros(num_nodes, dtype=torch.long)\n",
    "\n",
    "        # compute k-hop reachability matrix\n",
    "        reachability = compute_reachability_matrix(adjacency_matrix, max_walk_length)\n",
    "\n",
    "        # only keep columns corresponding to emerged nodes\n",
    "        # that will transact with future illicit nodes\n",
    "        reachability_to_illicit_transactors = reachability[:, future_illicit_transactor_ids]\n",
    "\n",
    "        # check if a node will have a node transacting with a future illicit in its neighbourhood\n",
    "        # this also check if the node will transact itself\n",
    "        has_new_illicit_in_neighborhood = (reachability_to_illicit_transactors.sum(axis=1) > 0).A1\n",
    "        \n",
    "        for node_id in range(num_nodes):\n",
    "            # Get the address for this node\n",
    "            node_address = id_to_address[node_id]\n",
    "            \n",
    "            # if it is specified to not label illicit nodes\n",
    "            if ignore_illict and node_address in all_illicit_addresses:\n",
    "                continue  \n",
    "\n",
    "            # if we also dont want to label nodes with illicit transaction history\n",
    "            elif ignore_previously_transacting_with_illicit and node_address in nodes_with_illicit_history:\n",
    "                continue\n",
    "\n",
    "            elif has_new_illicit_in_neighborhood[node_id]:\n",
    "                labels[node_id] = 1\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pjpykq19xgn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_classes(active_addresses, address_to_local_id, node_labels_df):\n",
    "    \"\"\"\n",
    "    Extract node class labels (1=illicit, 2=licit, 3=unknown).\n",
    "    \n",
    "    Args:\n",
    "        active_addresses: array/list of addresses active at current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "        node_labels_df: DataFrame with columns ['address', 'class']\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: node classes [num_nodes] with values 1 (illicit), 2 (licit), or 3 (unknown)\n",
    "    \"\"\"\n",
    "    num_nodes = len(active_addresses)\n",
    "    node_classes = torch.full((num_nodes,), 3, dtype=torch.long)  # default: unknown\n",
    "    \n",
    "    # create address -> class mapping\n",
    "    address_to_class = dict(zip(node_labels_df['address'], node_labels_df['class']))\n",
    "    \n",
    "    # assign classes\n",
    "    for addr in active_addresses:\n",
    "        if addr in address_to_class and addr in address_to_local_id:\n",
    "            local_id = address_to_local_id[addr]\n",
    "            node_classes[local_id] = address_to_class[addr]\n",
    "    \n",
    "    return node_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alcx0qhfefl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emergence_graph_at_timestep(\n",
    "    current_time_step: int,\n",
    "    nodes_df: pd.DataFrame,\n",
    "    edges_df: pd.DataFrame,\n",
    "    node_labels_df: pd.DataFrame,\n",
    "    keep_class_labels_as_features: bool = False,\n",
    "    use_distance_labels: bool = True,\n",
    "    max_walk_length: int = 2,\n",
    "    time_horizon: int = 3,\n",
    "    ignore_illict: bool = True,\n",
    "    ignore_previously_transacting_with_illicit: bool = True\n",
    ") -> Data:\n",
    "    \"\"\"\n",
    "    Build a temporal graph snapshot at a given time step for emergence prediction.\n",
    "    \n",
    "    This function creates a cumulative graph containing all nodes and edges that have\n",
    "    appeared up to and including the current time step, along with emergence labels\n",
    "    that predict future exposure to NEW illicit activity.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int\n",
    "            Current time step t for which to build the graph\n",
    "        nodes_df: pd.DataFrame\n",
    "            DataFrame with node features and columns ['address', 'Time step', ...]\n",
    "        edges_df: pd.DataFrame\n",
    "            DataFrame with transaction edges and columns ['Time step', 'input_address', 'output_address']\n",
    "        node_labels_df: pd.DataFrame\n",
    "            DataFrame with node class labels and columns ['address', 'class']\n",
    "            where class: 1 (illicit), 2 (licit), 3 (unknown)\n",
    "        keep_class_labels_as_features: bool, default=False\n",
    "            If True, include node class labels as features (may introduce label leakage)\n",
    "            If False, exclude class labels from features\n",
    "        use_distance_labels: bool, default=True\n",
    "            If True, labels are distances (0, 1, 2, ..., max_walk_length+1)\n",
    "            If False, labels are binary (0 or 1)\n",
    "        max_walk_length: int, default=2\n",
    "            Maximum number of hops to consider in the neighborhood\n",
    "        time_horizon: int, default=3\n",
    "            Number of future time steps to look ahead for emergence prediction\n",
    "        ignore_illict: bool, default=True\n",
    "            If True, nodes that are already illicit receive default labels\n",
    "        ignore_previously_transacting_with_illicit: bool, default=True\n",
    "            If True, nodes with illicit transaction history receive default labels\n",
    "    \n",
    "    Returns:\n",
    "        Data: PyTorch Geometric Data object with attributes:\n",
    "            - x: node features [num_nodes, num_features]\n",
    "            - edge_index: graph structure [2, num_edges]\n",
    "            - y: emergence labels [num_nodes] - PREDICTION TARGET\n",
    "            - node_class: ground truth node classes [num_nodes] - for visualization/analysis\n",
    "            - num_nodes: number of nodes in the graph\n",
    "            - time_step: current time step (for tracking)\n",
    "    \"\"\"\n",
    "    \n",
    "    # step 1: get all nodes and edges up to current time step\n",
    "    nodes_up_to_t = nodes_df[nodes_df['Time step'] <= current_time_step]\n",
    "    edges_up_to_t = edges_df[edges_df['Time step'] <= current_time_step]\n",
    "    \n",
    "    # step 2: get active addresses (thise that have already emerged at t)\n",
    "    active_addresses = nodes_up_to_t['address'].unique()\n",
    "    \n",
    "    # step 3: create local address-to-id mapping for this time step\n",
    "    address_to_local_id = {addr: idx for idx, addr in enumerate(active_addresses)}\n",
    "    \n",
    "    # step 4: pre-compute set of all illicit addresses (for efficiency)\n",
    "    all_illicit_addresses = set(node_labels_df[node_labels_df['class'] == 1]['address'].values)\n",
    "    \n",
    "    # step 5: Extract node features\n",
    "    node_features = extract_node_features(\n",
    "        nodes_up_to_t, \n",
    "        active_addresses, \n",
    "        address_to_local_id,\n",
    "        keep_class_labels_as_features=keep_class_labels_as_features\n",
    "    )\n",
    "    \n",
    "    # step 6: build edge index\n",
    "    edge_index = build_edge_index(edges_up_to_t, address_to_local_id)\n",
    "    \n",
    "    # step 7: generate emergence labels\n",
    "    labels = get_labels(\n",
    "        current_time_step=current_time_step,\n",
    "        edges_df=edges_df,\n",
    "        active_addresses=set(active_addresses),\n",
    "        active_address_to_local_id=address_to_local_id,\n",
    "        all_illicit_addresses=all_illicit_addresses,\n",
    "        edge_index_at_t=edge_index,\n",
    "        use_distance_labels=use_distance_labels,\n",
    "        max_walk_length=max_walk_length,\n",
    "        time_horizon=time_horizon,\n",
    "        ignore_illict=ignore_illict,\n",
    "        ignore_previously_transacting_with_illicit=ignore_previously_transacting_with_illicit\n",
    "    )\n",
    "    \n",
    "    # step 8: extract node classes (this is modtly for visualization / analysis)\n",
    "    node_classes = extract_node_classes(active_addresses, address_to_local_id, node_labels_df)\n",
    "    \n",
    "    # step 9: create PyTorch Geometric Data object\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        y=labels,\n",
    "        node_class=node_classes,\n",
    "        num_nodes=len(active_addresses),\n",
    "        time_step=current_time_step\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
