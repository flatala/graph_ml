{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e472414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project root: c:\\Users\\luket\\Documents\\Fork\\graph_ml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = Path.cwd()\n",
    "while project_root != project_root.parent and not (project_root / \"code_lib\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "if not (project_root / \"code_lib\").exists():\n",
    "    raise RuntimeError(f\"Unable to locate 'code_lib' starting from {Path.cwd()}\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Using project root: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6557c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import optuna\n",
    "\n",
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "\n",
    "import torchmetrics.functional as tmf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "from torch_geometric.nn.models.tgn import LastNeighborLoader\n",
    "\n",
    "from code_lib.temporal_node_classification_builder import (\n",
    "    TemporalNodeClassificationBuilder, load_elliptic_data\n",
    ")\n",
    "\n",
    "from torch_geometric.nn.models.tgn import (\n",
    "    TGNMemory,\n",
    "    LastNeighborLoader,\n",
    "    IdentityMessage,\n",
    "    MeanAggregator,\n",
    ")\n",
    "\n",
    "from code_lib.temporal_edge_builder import TemporalEdgeBuilder\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896fe43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f57607ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshots built: 49 graphs\n",
      "Event stream events total: 4170754\n",
      "Train -> events: 1547601, t-range: [5, 26]\n",
      "Val   -> events:  121047, t-range: [27, 31]\n",
      "Test  -> events:  765003, t-range: [32, 40]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# 2. Library imports\n",
    "from code_lib.temporal_node_classification_builder import (\n",
    "    TemporalNodeClassificationBuilder,\n",
    "    load_elliptic_data,\n",
    ")\n",
    "from code_lib.temporal_edge_builder import TemporalEdgeBuilder  # optional (see below)\n",
    "\n",
    "# 3. Load nodes + raw edges\n",
    "DATA_DIR = project_root / \"elliptic_dataset\"\n",
    "nodes_df, raw_edges = load_elliptic_data(str(DATA_DIR), use_temporal_features=True)\n",
    "\n",
    "# --- Option A: use raw edges (fastest, no extra weighting) --------------------\n",
    "edges_df = raw_edges.copy()\n",
    "use_edge_weights = False\n",
    "edge_weight_col = None\n",
    "\n",
    "# --- Option B (optional): build decayed edge weights for every timestep -------\n",
    "# Uncomment if you really need weighted edges; this can take several minutes.\n",
    "# edge_builder = TemporalEdgeBuilder(raw_edges, decay_lambda=0.1, verbose=True)\n",
    "# edges_df = edge_builder.build_temporal_edge_sequence(\n",
    "#     start_timestep=int(raw_edges[\"Time step\"].min()),\n",
    "#     end_timestep=int(raw_edges[\"Time step\"].max()),\n",
    "# )\n",
    "# use_edge_weights = True\n",
    "# edge_weight_col = \"temporal_weight\"\n",
    "\n",
    "# 4. Instantiate the node builder with the full edge history\n",
    "builder = TemporalNodeClassificationBuilder(\n",
    "    nodes_df=nodes_df,\n",
    "    edges_df=edges_df,\n",
    "    include_class_as_feature=False,\n",
    "    add_temporal_features=True,\n",
    "    add_edge_weights=use_edge_weights,\n",
    "    edge_weight_col=edge_weight_col,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# 5. Build snapshots + event stream\n",
    "snapshots = builder.build_snapshot_sequence(return_node_metadata=True)\n",
    "event_stream = builder.build_event_stream(dense=False, include_edge_attr=False)\n",
    "\n",
    "print(f\"Snapshots built: {len(snapshots)} graphs\")\n",
    "print(f\"Event stream events total: {event_stream.src.numel()}\")\n",
    "\n",
    "# 6. Temporal splits that now span all timesteps\n",
    "splits = builder.get_event_stream_split(\n",
    "    train_timesteps=(5, 26),\n",
    "    val_timesteps=(27, 31),\n",
    "    test_timesteps=(32, 40),\n",
    "    dense=False,\n",
    "    include_edge_attr=False,\n",
    ")\n",
    "\n",
    "for name, data in splits.items():\n",
    "    count = int(data.t.numel())\n",
    "    min_t = int(data.t.min()) if count else \"NA\"\n",
    "    max_t = int(data.t.max()) if count else \"NA\"\n",
    "    print(f\"{name.capitalize():5s} -> events: {count:7d}, t-range: [{min_t}, {max_t}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc0c867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.unique(splits[\"train\"].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34a53fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(data, batch_size, shuffle):\n",
    "    return TemporalDataLoader(data, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff2a49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMessage(nn.Module):\n",
    "    def __init__(self, raw_msg_dim, hidden_dim, out_dim, dropout, memory_dim, time_dim):\n",
    "        super().__init__()\n",
    "        in_dim = 2 * memory_dim + raw_msg_dim + time_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "        )\n",
    "        self.out_channels = out_dim\n",
    "\n",
    "    def forward(self, z_src, z_dst, raw_msg, t_enc):\n",
    "        h = torch.cat([z_src, z_dst, raw_msg, t_enc], dim=-1)\n",
    "        return self.net(h)\n",
    "\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.lin2 = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = torch.cat([z_src, z_dst], dim=-1)\n",
    "        h = self.dropout(F.relu(self.lin1(h)))\n",
    "        return self.lin2(h).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4af65e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrialConfig:\n",
    "    memory_dim: int\n",
    "    time_dim: int\n",
    "    msg_hidden: int\n",
    "    msg_out: int\n",
    "    decoder_hidden: int\n",
    "    neighbor_size: int\n",
    "    batch_size: int\n",
    "    lr: float\n",
    "    weight_decay: float\n",
    "    dropout: float\n",
    "    epochs: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "15632449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_modules(config: TrialConfig, raw_msg_dim: int, num_nodes: int):\n",
    "    message_module = MLPMessage(\n",
    "        raw_msg_dim=raw_msg_dim,\n",
    "        hidden_dim=config.msg_hidden,\n",
    "        out_dim=config.msg_out,\n",
    "        dropout=config.dropout,\n",
    "        memory_dim=config.memory_dim,\n",
    "        time_dim=config.time_dim,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "\n",
    "    memory = TGNMemory(\n",
    "        num_nodes=num_nodes,\n",
    "        raw_msg_dim=raw_msg_dim,  # event_stream.msg.size(-1)\n",
    "        memory_dim=config.memory_dim,\n",
    "        time_dim=config.time_dim,\n",
    "        message_module=message_module,\n",
    "        aggregator_module=MeanAggregator(),\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    neighbor_loader = LastNeighborLoader(\n",
    "        num_nodes=num_nodes,\n",
    "        size=config.neighbor_size,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    decoder = LinkPredictor(\n",
    "        in_dim=config.memory_dim * 2,\n",
    "        hidden_dim=config.decoder_hidden,\n",
    "        dropout=config.dropout,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    params = list(memory.parameters()) + list(decoder.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=config.lr, weight_decay=config.weight_decay)\n",
    "\n",
    "    return memory, neighbor_loader, decoder, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b9ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def _gather_embeddings(memory, batch, assoc_buffer):\n",
    "    n_id = torch.cat([batch.src, batch.dst]).unique()\n",
    "    z_mem, _ = memory(n_id)  # shape [|n_id|, memory_dim]\n",
    "\n",
    "    assoc_buffer[n_id] = torch.arange(n_id.size(0), device=assoc_buffer.device)\n",
    "    src_idx = assoc_buffer[batch.src]\n",
    "    dst_idx = assoc_buffer[batch.dst]\n",
    "    assoc_buffer[n_id] = -1  # reset mapping for next batch\n",
    "\n",
    "    z_src = z_mem[src_idx]\n",
    "    z_dst = z_mem[dst_idx]\n",
    "    return z_src, z_dst\n",
    "\n",
    "def run_epoch(loader, memory, neighbor_loader, decoder, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    memory.train(is_train)\n",
    "    decoder.train(is_train)\n",
    "\n",
    "    memory.reset_state()\n",
    "    neighbor_loader.reset_state()\n",
    "    assoc_buffer = torch.full(\n",
    "        (memory.num_nodes,), -1, device=DEVICE, dtype=torch.long\n",
    "    )\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_events = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        z_src, z_dst = _gather_embeddings(memory, batch, assoc_buffer)\n",
    "        logits = decoder(z_src, z_dst)\n",
    "        loss = criterion(logits, batch.y.float())\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(memory.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            memory.detach()\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "\n",
    "        num_events = batch.src.size(0)\n",
    "        total_loss += float(loss.item()) * num_events\n",
    "        total_events += num_events\n",
    "\n",
    "    return total_loss / max(total_events, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader, memory, neighbor_loader, decoder):\n",
    "    memory.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    memory.reset_state()\n",
    "    neighbor_loader.reset_state()\n",
    "    assoc_buffer = torch.full(\n",
    "        (memory.num_nodes,), -1, device=DEVICE, dtype=torch.long\n",
    "    )\n",
    "\n",
    "    preds, targets = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "\n",
    "        z_src, z_dst = _gather_embeddings(memory, batch, assoc_buffer)\n",
    "        logits = decoder(z_src, z_dst)\n",
    "        preds.append(torch.sigmoid(logits).cpu())\n",
    "        targets.append(batch.y.float().cpu())\n",
    "\n",
    "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
    "        neighbor_loader.insert(batch.src, batch.dst)\n",
    "        memory.detach()\n",
    "\n",
    "    if not preds:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    y_score = torch.cat(preds)\n",
    "    y_true = torch.cat(targets).long()\n",
    "\n",
    "    ap = tmf.average_precision(y_score, y_true, task=\"binary\")\n",
    "    f1 = tmf.f1_score((y_score > 0.5).long(), y_true, task=\"binary\")\n",
    "    return ap, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69ac3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_msg_dim = event_stream.msg.size(-1)\n",
    "num_nodes = builder.nodes_df[\"address\"].nunique()\n",
    "\n",
    "def suggest_config(trial) -> TrialConfig:\n",
    "    return TrialConfig(\n",
    "        memory_dim=trial.suggest_categorical(\"memory_dim\", [32, 64, 128]),\n",
    "        time_dim=trial.suggest_categorical(\"time_dim\", [4, 8, 16]),\n",
    "        msg_hidden=trial.suggest_categorical(\"msg_hidden\", [32, 64, 128]),\n",
    "        msg_out=trial.suggest_categorical(\"msg_out\", [16, 32, 64]),\n",
    "        decoder_hidden=trial.suggest_categorical(\"decoder_hidden\", [32, 64, 128]),\n",
    "        neighbor_size=trial.suggest_categorical(\"neighbor_size\", [10, 20, 50]),\n",
    "        batch_size=trial.suggest_categorical(\"batch_size\", [2048, 4096, 8192]),\n",
    "        lr=trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True),\n",
    "        weight_decay=trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True),\n",
    "        dropout=trial.suggest_float(\"dropout\", 0.0, 0.4),\n",
    "        epochs=trial.suggest_int(\"epochs\", 5, 15),\n",
    "    )\n",
    "\n",
    "train_loader_cache: dict[int, TemporalDataLoader] = {}\n",
    "val_loader_cache: dict[int, TemporalDataLoader] = {}\n",
    "\n",
    "def get_loaders(batch_size):\n",
    "    if batch_size not in train_loader_cache:\n",
    "        train_loader_cache[batch_size] = make_loader(splits[\"train\"], batch_size, shuffle=True)\n",
    "        val_loader_cache[batch_size] = make_loader(splits[\"val\"], batch_size, shuffle=False)\n",
    "    return train_loader_cache[batch_size], val_loader_cache[batch_size]\n",
    "\n",
    "def objective(trial):\n",
    "    config = suggest_config(trial)\n",
    "    train_loader, val_loader = get_loaders(config.batch_size)\n",
    "\n",
    "    memory, neighbor_loader, decoder, optimizer = build_modules(\n",
    "        config, raw_msg_dim, num_nodes\n",
    "    )\n",
    "\n",
    "    best_ap = 0.0\n",
    "    for epoch in range(config.epochs):\n",
    "        run_epoch(train_loader, memory, neighbor_loader, decoder, optimizer)\n",
    "        val_ap, _ = evaluate(val_loader, memory, neighbor_loader, decoder)\n",
    "        trial.report(val_ap, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        best_ap = max(best_ap, val_ap)\n",
    "\n",
    "    return best_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cbdf8bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 10:53:04,399] A new study created in memory with name: no-name-40bb3244-e757-47ca-afaa-82c073713ff4\n",
      "[W 2025-11-08 10:55:22,716] Trial 0 failed with parameters: {'memory_dim': 32, 'time_dim': 8, 'msg_hidden': 32, 'msg_out': 16, 'decoder_hidden': 64, 'neighbor_size': 10, 'batch_size': 2048, 'lr': 0.001642281355380936, 'weight_decay': 0.00036853802741068496, 'dropout': 0.041180774022345594, 'epochs': 6} because of the following error: RuntimeError('Detected the following values in `target`: tensor([0, 1, 2]) but expected only the following values [0, 1].').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\luket\\AppData\\Local\\Temp\\ipykernel_29292\\253380575.py\", line 39, in objective\n",
      "    val_ap, _ = evaluate(val_loader, memory, neighbor_loader, decoder)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\luket\\AppData\\Local\\Temp\\ipykernel_29292\\3960535986.py\", line 88, in evaluate\n",
      "    ap = tmf.average_precision(y_score, y_true, task=\"binary\")\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\average_precision.py\", line 460, in average_precision\n",
      "    return binary_average_precision(preds, target, thresholds, ignore_index, validate_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\average_precision.py\", line 150, in binary_average_precision\n",
      "    _binary_precision_recall_curve_tensor_validation(preds, target, ignore_index)\n",
      "  File \"c:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\precision_recall_curve.py\", line 158, in _binary_precision_recall_curve_tensor_validation\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Detected the following values in `target`: tensor([0, 1, 2]) but expected only the following values [0, 1].\n",
      "[W 2025-11-08 10:55:22,724] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Detected the following values in `target`: tensor([0, 1, 2]) but expected only the following values [0, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# adjust trial count as needed\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m, study.best_trial.value)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest params:\u001b[39m\u001b[33m\"\u001b[39m, study.best_trial.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config.epochs):\n\u001b[32m     38\u001b[39m     run_epoch(train_loader, memory, neighbor_loader, decoder, optimizer)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     val_ap, _ = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     trial.report(val_ap, step=epoch)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trial.should_prune():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(loader, memory, neighbor_loader, decoder)\u001b[39m\n\u001b[32m     85\u001b[39m y_score = torch.cat(preds)\n\u001b[32m     86\u001b[39m y_true = torch.cat(targets).long()\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m ap = \u001b[43mtmf\u001b[49m\u001b[43m.\u001b[49m\u001b[43maverage_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m f1 = tmf.f1_score((y_score > \u001b[32m0.5\u001b[39m).long(), y_true, task=\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ap, f1\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\average_precision.py:460\u001b[39m, in \u001b[36maverage_precision\u001b[39m\u001b[34m(preds, target, task, thresholds, num_classes, num_labels, average, ignore_index, validate_args)\u001b[39m\n\u001b[32m    458\u001b[39m task = ClassificationTask.from_str(task)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task == ClassificationTask.BINARY:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_average_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task == ClassificationTask.MULTICLASS:\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(num_classes, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\average_precision.py:150\u001b[39m, in \u001b[36mbinary_average_precision\u001b[39m\u001b[34m(preds, target, thresholds, ignore_index, validate_args)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate_args:\n\u001b[32m    149\u001b[39m     _binary_precision_recall_curve_arg_validation(thresholds, ignore_index)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[43m_binary_precision_recall_curve_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m preds, target, thresholds = _binary_precision_recall_curve_format(preds, target, thresholds, ignore_index)\n\u001b[32m    152\u001b[39m state = _binary_precision_recall_curve_update(preds, target, thresholds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luket\\Documents\\Fork\\graph_ml\\.venv\\Lib\\site-packages\\torchmetrics\\functional\\classification\\precision_recall_curve.py:158\u001b[39m, in \u001b[36m_binary_precision_recall_curve_tensor_validation\u001b[39m\u001b[34m(preds, target, ignore_index)\u001b[39m\n\u001b[32m    156\u001b[39m     check = torch.any((unique_values != \u001b[32m0\u001b[39m) & (unique_values != \u001b[32m1\u001b[39m) & (unique_values != ignore_index))\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    159\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected the following values in `target`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but expected only\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m the following values \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[32m0\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mignore_index\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m[ignore_index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    161\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Detected the following values in `target`: tensor([0, 1, 2]) but expected only the following values [0, 1]."
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  # adjust trial count as needed\n",
    "\n",
    "print(\"Best trial:\", study.best_trial.value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
