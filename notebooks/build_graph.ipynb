{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72ba130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df175b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../elliptic_dataset\"\n",
    "WALLETS_FEATURES = \"wallets_features.csv\"\n",
    "WALLETS_CLASSES = \"wallets_classes.csv\"\n",
    "EDGES_PREFIX = \"AddrTxAddr_edgelist_part_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8ebbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import pandas as pd\n",
    "\n",
    "def load_parts(data_dir: str, base: str) -> pd.DataFrame:\n",
    "    paths = glob.glob(os.path.join(data_dir, f\"{base}*.csv\"))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No files found for pattern {base}_part_*.csv in {data_dir}\")\n",
    "\n",
    "    paths.sort(key=lambda p: int(re.search(r'_part_(\\d+)\\.csv$', p).group(1)))\n",
    "    return pd.concat((pd.read_csv(p) for p in paths), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1a316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(os.path.join(DATA_DIR, WALLETS_FEATURES))\n",
    "node_labels = pd.read_csv(os.path.join(DATA_DIR, WALLETS_CLASSES))\n",
    "edges_with_edge_labels = load_parts(DATA_DIR, EDGES_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fcf59a",
   "metadata": {},
   "source": [
    "group nodes by timesteps and see how many nodes we get at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ee60e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Time step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "address",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f6016ff4-111b-4c63-93a1-44c570bb9c0e",
       "rows": [
        [
         "1",
         "34853"
        ],
        [
         "2",
         "24847"
        ],
        [
         "3",
         "20137"
        ],
        [
         "4",
         "21030"
        ],
        [
         "5",
         "23261"
        ],
        [
         "6",
         "11754"
        ],
        [
         "7",
         "21537"
        ],
        [
         "8",
         "25762"
        ],
        [
         "9",
         "19747"
        ],
        [
         "10",
         "32763"
        ],
        [
         "11",
         "21737"
        ],
        [
         "12",
         "10076"
        ],
        [
         "13",
         "23708"
        ],
        [
         "14",
         "5573"
        ],
        [
         "15",
         "14133"
        ],
        [
         "16",
         "8097"
        ],
        [
         "17",
         "16325"
        ],
        [
         "18",
         "5566"
        ],
        [
         "19",
         "10076"
        ],
        [
         "20",
         "29451"
        ],
        [
         "21",
         "33764"
        ],
        [
         "22",
         "27413"
        ],
        [
         "23",
         "13587"
        ],
        [
         "24",
         "16651"
        ],
        [
         "25",
         "17040"
        ],
        [
         "26",
         "15949"
        ],
        [
         "27",
         "8435"
        ],
        [
         "28",
         "4940"
        ],
        [
         "29",
         "16216"
        ],
        [
         "30",
         "9089"
        ],
        [
         "31",
         "14726"
        ],
        [
         "32",
         "16133"
        ],
        [
         "33",
         "13955"
        ],
        [
         "34",
         "12940"
        ],
        [
         "35",
         "22655"
        ],
        [
         "36",
         "31764"
        ],
        [
         "37",
         "15785"
        ],
        [
         "38",
         "16824"
        ],
        [
         "39",
         "11378"
        ],
        [
         "40",
         "26723"
        ],
        [
         "41",
         "22253"
        ],
        [
         "42",
         "32531"
        ],
        [
         "43",
         "24600"
        ],
        [
         "44",
         "19668"
        ],
        [
         "45",
         "25060"
        ],
        [
         "46",
         "18184"
        ],
        [
         "47",
         "21079"
        ],
        [
         "48",
         "18717"
        ],
        [
         "49",
         "12199"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 49
       }
      },
      "text/plain": [
       "Time step\n",
       "1     34853\n",
       "2     24847\n",
       "3     20137\n",
       "4     21030\n",
       "5     23261\n",
       "6     11754\n",
       "7     21537\n",
       "8     25762\n",
       "9     19747\n",
       "10    32763\n",
       "11    21737\n",
       "12    10076\n",
       "13    23708\n",
       "14     5573\n",
       "15    14133\n",
       "16     8097\n",
       "17    16325\n",
       "18     5566\n",
       "19    10076\n",
       "20    29451\n",
       "21    33764\n",
       "22    27413\n",
       "23    13587\n",
       "24    16651\n",
       "25    17040\n",
       "26    15949\n",
       "27     8435\n",
       "28     4940\n",
       "29    16216\n",
       "30     9089\n",
       "31    14726\n",
       "32    16133\n",
       "33    13955\n",
       "34    12940\n",
       "35    22655\n",
       "36    31764\n",
       "37    15785\n",
       "38    16824\n",
       "39    11378\n",
       "40    26723\n",
       "41    22253\n",
       "42    32531\n",
       "43    24600\n",
       "44    19668\n",
       "45    25060\n",
       "46    18184\n",
       "47    21079\n",
       "48    18717\n",
       "49    12199\n",
       "Name: address, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_per_time_step = nodes.groupby('Time step')['address'].nunique()\n",
    "nodes_per_time_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b5831",
   "metadata": {},
   "source": [
    "Investigate how do timesteps work - is it timestep in which the node inetracts or if it appears at one it remains there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b553b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique addresses: 822942\n",
      "Total rows in nodes: 1268260\n",
      "\n",
      "Addresses appearing in:\n",
      "  1 time step: 761455\n",
      "  2-5 time steps: 59947\n",
      "  6-10 time steps: 1315\n",
      "  >10 time steps: 225\n",
      "  Max time steps: 47\n",
      "\n",
      "1111DAYXhoxZx2tsRnzi... appears in 6 time steps: [np.int64(25), np.int64(29), np.int64(39), np.int64(39), np.int64(43), np.int64(43), np.int64(47), np.int64(48)]\n",
      "111khWGs3Mj7UgKT7aS6... appears in 2 time steps: [np.int64(14), np.int64(34), np.int64(34), np.int64(34), np.int64(34)]\n",
      "1121A3vrYYduVPMnfS87... appears in 3 time steps: [np.int64(9), np.int64(9), np.int64(23), np.int64(42)]\n",
      "112467zLZa5J6JLmvDr3... appears in 2 time steps: [np.int64(36), np.int64(37)]\n",
      "1125mk1uScXXFi5MfR6g... appears in 3 time steps: [np.int64(36), np.int64(36), np.int64(36), np.int64(37), np.int64(38)]\n",
      "1126nC9nY73uYEuJrvgp... appears in 2 time steps: [np.int64(19), np.int64(24)]\n",
      "11287dmR4AcCWg8g8jfn... appears in 3 time steps: [np.int64(25), np.int64(38), np.int64(43)]\n",
      "1128R85E7agQiFpm7N6C... appears in 2 time steps: [np.int64(2), np.int64(20), np.int64(20)]\n",
      "112D2ENnUSsWrQZFLBvG... appears in 2 time steps: [np.int64(11), np.int64(20)]\n",
      "112EFmY89R1cFdvoAuxM... appears in 2 time steps: [np.int64(9), np.int64(12)]\n"
     ]
    }
   ],
   "source": [
    "address_time_step_counts = nodes.groupby('address')['Time step'].nunique()\n",
    "address_time_step_counts.value_counts().sort_index()\n",
    "\n",
    "print(f\"Total unique addresses: {len(address_time_step_counts)}\")\n",
    "print(f\"Total rows in nodes: {len(nodes)}\")\n",
    "print(f\"\\nAddresses appearing in:\")\n",
    "print(f\"  1 time step: {(address_time_step_counts == 1).sum()}\")\n",
    "print(f\"  2-5 time steps: {((address_time_step_counts >= 2) & (address_time_step_counts <= 5)).sum()}\")\n",
    "print(f\"  6-10 time steps: {((address_time_step_counts >= 6) & (address_time_step_counts <= 10)).sum()}\")\n",
    "print(f\"  >10 time steps: {(address_time_step_counts > 10).sum()}\")\n",
    "print(f\"  Max time steps: {address_time_step_counts.max()}\\n\")\n",
    "\n",
    "multi_time_step_addresses = address_time_step_counts[address_time_step_counts > 1].head(10)\n",
    "for addr, count in multi_time_step_addresses.items():\n",
    "    time_steps = nodes[nodes['address'] == addr]['Time step'].values\n",
    "    print(f\"{addr[:20]}... appears in {count} time steps: {sorted(time_steps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1f40d",
   "metadata": {},
   "source": [
    "### Building time-step graphs\n",
    "At each time step we build a graph that contaisn all the nodes that have interacted with other nodes up to that time step. A graph at time $t$, let's call it $G_t$, will contain all the nodes from $G_{t-1}$, as well as all the nodes that have had their first tarnsactions at time $t$. This way we don't have to explictly model the evolving structure of the graph and can run baselines such as a normal GCN or a EvolveGCN - the targets at time $t$ will be simply weather a node makes a tarnsaction with an illict node at time $t + 1$. Then if we predict for a bunch of related nodes that they will make a tarnsaction to some illict node, that  indicates that an illict node should appear somehwere in that region. This is a bsaeline, for proper emergence we will need an approach like TGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a70e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0bced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time steps: 49\n"
     ]
    }
   ],
   "source": [
    "time_steps = sorted(nodes['Time step'].unique())\n",
    "print(f\"Total time steps: {len(time_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c686984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique addresses across all time: 822942\n"
     ]
    }
   ],
   "source": [
    "all_addresses = nodes['address'].unique()\n",
    "\n",
    "# dict of adresses mapped to unique ids to index nodes in the grapj\n",
    "address_to_id = {addr: idx for idx, addr in enumerate(all_addresses)}\n",
    "\n",
    "num_nodes_total = len(all_addresses)\n",
    "print(f\"Total unique addresses across all time: {num_nodes_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b35b6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "address",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Time step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_txs_as_sender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_txs_as receiver",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_block_appeared_in",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "last_block_appeared_in",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lifetime_in_blocks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_txs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_sent_block",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_received_block",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_timesteps_appeared_in",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_transacted_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_transacted_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_transacted_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_transacted_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_transacted_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_sent_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_sent_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_sent_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_sent_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_sent_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_received_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_received_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_received_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_received_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "btc_received_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_as_share_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_as_share_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_as_share_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_as_share_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fees_as_share_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_txs_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_txs_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_txs_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_txs_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_txs_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_input_txs_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_input_txs_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_input_txs_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_input_txs_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_input_txs_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_output_txs_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_output_txs_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_output_txs_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_output_txs_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blocks_btwn_output_txs_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_addr_transacted_multiple",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transacted_w_address_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transacted_w_address_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transacted_w_address_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transacted_w_address_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "transacted_w_address_median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "eb6f59f0-4119-47f8-b0db-7c8317526da8",
       "rows": [
        [
         "0",
         "111112TykSw72ztDN2WJger4cynzWYC5w",
         "25",
         "0.0",
         "1.0",
         "439586.0",
         "439586.0",
         "0.0",
         "1.0",
         "0.0",
         "439586.0",
         "1.0",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.0106281",
         "0.00704228",
         "0.00704228",
         "0.00704228",
         "0.00704228",
         "0.00704228",
         "1.16237288734953e-05",
         "1.16237288734953e-05",
         "1.16237288734953e-05",
         "1.16237288734953e-05",
         "1.16237288734953e-05",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "24.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "2"
        ],
        [
         "1",
         "1111DAYXhoxZx2tsRnzimfozo783x1yC2",
         "25",
         "0.0",
         "8.0",
         "439589.0",
         "485959.0",
         "46370.0",
         "8.0",
         "0.0",
         "439589.0",
         "6.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.00237122",
         "0.00012224",
         "0.00057984",
         "0.0002964025",
         "0.00024192",
         "0.0022170327743116",
         "0.0001214933074285",
         "0.0005230928421983",
         "0.0002771290967889",
         "0.0002374776409273",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "8.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3"
        ],
        [
         "2",
         "1111DAYXhoxZx2tsRnzimfozo783x1yC2",
         "29",
         "0.0",
         "8.0",
         "439589.0",
         "485959.0",
         "46370.0",
         "8.0",
         "0.0",
         "439589.0",
         "6.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.00237122",
         "0.00012224",
         "0.00057984",
         "0.0002964025",
         "0.00024192",
         "0.0022170327743116",
         "0.0001214933074285",
         "0.0005230928421983",
         "0.0002771290967889",
         "0.0002374776409273",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "8.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3"
        ],
        [
         "3",
         "1111DAYXhoxZx2tsRnzimfozo783x1yC2",
         "39",
         "0.0",
         "8.0",
         "439589.0",
         "485959.0",
         "46370.0",
         "8.0",
         "0.0",
         "439589.0",
         "6.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.00237122",
         "0.00012224",
         "0.00057984",
         "0.0002964025",
         "0.00024192",
         "0.0022170327743116",
         "0.0001214933074285",
         "0.0005230928421983",
         "0.0002771290967889",
         "0.0002374776409273",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "8.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3"
        ],
        [
         "4",
         "1111DAYXhoxZx2tsRnzimfozo783x1yC2",
         "39",
         "0.0",
         "8.0",
         "439589.0",
         "485959.0",
         "46370.0",
         "8.0",
         "0.0",
         "439589.0",
         "6.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.27304573",
         "0.00390045",
         "0.13377712",
         "0.03413071625",
         "0.01435218",
         "0.00237122",
         "0.00012224",
         "0.00057984",
         "0.0002964025",
         "0.00024192",
         "0.0022170327743116",
         "0.0001214933074285",
         "0.0005230928421983",
         "0.0002771290967889",
         "0.0002374776409273",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "46370.0",
         "0.0",
         "20164.0",
         "6624.28571428571",
         "8060.0",
         "0.0",
         "8.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "3"
        ]
       ],
       "shape": {
        "columns": 58,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>Time step</th>\n",
       "      <th>num_txs_as_sender</th>\n",
       "      <th>num_txs_as receiver</th>\n",
       "      <th>first_block_appeared_in</th>\n",
       "      <th>last_block_appeared_in</th>\n",
       "      <th>lifetime_in_blocks</th>\n",
       "      <th>total_txs</th>\n",
       "      <th>first_sent_block</th>\n",
       "      <th>first_received_block</th>\n",
       "      <th>...</th>\n",
       "      <th>blocks_btwn_output_txs_max</th>\n",
       "      <th>blocks_btwn_output_txs_mean</th>\n",
       "      <th>blocks_btwn_output_txs_median</th>\n",
       "      <th>num_addr_transacted_multiple</th>\n",
       "      <th>transacted_w_address_total</th>\n",
       "      <th>transacted_w_address_min</th>\n",
       "      <th>transacted_w_address_max</th>\n",
       "      <th>transacted_w_address_mean</th>\n",
       "      <th>transacted_w_address_median</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111112TykSw72ztDN2WJger4cynzWYC5w</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>439586.0</td>\n",
       "      <td>439586.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439586.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111DAYXhoxZx2tsRnzimfozo783x1yC2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>485959.0</td>\n",
       "      <td>46370.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20164.0</td>\n",
       "      <td>6624.285714</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111DAYXhoxZx2tsRnzimfozo783x1yC2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>485959.0</td>\n",
       "      <td>46370.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20164.0</td>\n",
       "      <td>6624.285714</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111DAYXhoxZx2tsRnzimfozo783x1yC2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>485959.0</td>\n",
       "      <td>46370.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20164.0</td>\n",
       "      <td>6624.285714</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1111DAYXhoxZx2tsRnzimfozo783x1yC2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>485959.0</td>\n",
       "      <td>46370.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439589.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20164.0</td>\n",
       "      <td>6624.285714</td>\n",
       "      <td>8060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             address  Time step  num_txs_as_sender  \\\n",
       "0  111112TykSw72ztDN2WJger4cynzWYC5w         25                0.0   \n",
       "1  1111DAYXhoxZx2tsRnzimfozo783x1yC2         25                0.0   \n",
       "2  1111DAYXhoxZx2tsRnzimfozo783x1yC2         29                0.0   \n",
       "3  1111DAYXhoxZx2tsRnzimfozo783x1yC2         39                0.0   \n",
       "4  1111DAYXhoxZx2tsRnzimfozo783x1yC2         39                0.0   \n",
       "\n",
       "   num_txs_as receiver  first_block_appeared_in  last_block_appeared_in  \\\n",
       "0                  1.0                 439586.0                439586.0   \n",
       "1                  8.0                 439589.0                485959.0   \n",
       "2                  8.0                 439589.0                485959.0   \n",
       "3                  8.0                 439589.0                485959.0   \n",
       "4                  8.0                 439589.0                485959.0   \n",
       "\n",
       "   lifetime_in_blocks  total_txs  first_sent_block  first_received_block  ...  \\\n",
       "0                 0.0        1.0               0.0              439586.0  ...   \n",
       "1             46370.0        8.0               0.0              439589.0  ...   \n",
       "2             46370.0        8.0               0.0              439589.0  ...   \n",
       "3             46370.0        8.0               0.0              439589.0  ...   \n",
       "4             46370.0        8.0               0.0              439589.0  ...   \n",
       "\n",
       "   blocks_btwn_output_txs_max  blocks_btwn_output_txs_mean  \\\n",
       "0                         0.0                     0.000000   \n",
       "1                     20164.0                  6624.285714   \n",
       "2                     20164.0                  6624.285714   \n",
       "3                     20164.0                  6624.285714   \n",
       "4                     20164.0                  6624.285714   \n",
       "\n",
       "   blocks_btwn_output_txs_median  num_addr_transacted_multiple  \\\n",
       "0                            0.0                           0.0   \n",
       "1                         8060.0                           0.0   \n",
       "2                         8060.0                           0.0   \n",
       "3                         8060.0                           0.0   \n",
       "4                         8060.0                           0.0   \n",
       "\n",
       "   transacted_w_address_total  transacted_w_address_min  \\\n",
       "0                        24.0                       1.0   \n",
       "1                         8.0                       1.0   \n",
       "2                         8.0                       1.0   \n",
       "3                         8.0                       1.0   \n",
       "4                         8.0                       1.0   \n",
       "\n",
       "   transacted_w_address_max  transacted_w_address_mean  \\\n",
       "0                       1.0                        1.0   \n",
       "1                       1.0                        1.0   \n",
       "2                       1.0                        1.0   \n",
       "3                       1.0                        1.0   \n",
       "4                       1.0                        1.0   \n",
       "\n",
       "   transacted_w_address_median  class  \n",
       "0                          1.0      2  \n",
       "1                          1.0      3  \n",
       "2                          1.0      3  \n",
       "3                          1.0      3  \n",
       "4                          1.0      3  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_with_labels = nodes.merge(node_labels, on='address', how='left')\n",
    "nodes_with_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57845421",
   "metadata": {},
   "source": [
    "Let's define a helper that will extract node features for each time-step graph $G_t$. If a node reappears at multiple time steps we use the latest node features in th graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_features(nodes_up_to_t, active_addresses, address_to_local_id, keep_class_labels_as_features: bool = True):\n",
    "    \"\"\"\n",
    "    Extract latest features for each active node (OPTIMIZED VERSION).\n",
    "    When a node appears multiple times, use the most recent feature values.\n",
    "    \n",
    "    Args:\n",
    "        nodes_up_to_t: DataFrame with node data up to current time step\n",
    "        active_addresses: array/list of addresses active (have emerged) up to current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: node features [num_nodes, num_features]\n",
    "    \"\"\"\n",
    "\n",
    "    # select only the feature columns\n",
    "    # NOTE: node class should be a feature !!!\n",
    "    # to predict future emrgence we can assume we will know what are the currently illict nodes!!!\n",
    "    if keep_class_labels_as_features:\n",
    "        feature_cols = [col for col in nodes_up_to_t.columns \n",
    "                    if col not in ['address', 'Time step']]\n",
    "    else:    \n",
    "        feature_cols = [col for col in nodes_up_to_t.columns \n",
    "                    if col not in ['address', 'Time step', 'class']]\n",
    "    \n",
    "    # use groupby to get last row per address \n",
    "    # we sort because for each node we want to keep its latest feature set in case a node reappears at multiple time steps\n",
    "    nodes_sorted = nodes_up_to_t.sort_values('Time step')\n",
    "    latest_per_address = nodes_sorted.groupby('address', as_index=True)[feature_cols].last()\n",
    "    \n",
    "    # prepare an empty array\n",
    "    num_features = len(feature_cols)\n",
    "    num_active_nodes = len(active_addresses)\n",
    "    node_features = np.zeros((num_active_nodes, num_features))\n",
    "    \n",
    "    # populate features\n",
    "    for addr in active_addresses:\n",
    "        if addr in latest_per_address.index:\n",
    "            local_id = address_to_local_id[addr]\n",
    "            node_features[local_id] = latest_per_address.loc[addr].values\n",
    "    \n",
    "    return torch.tensor(node_features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2529e4e8",
   "metadata": {},
   "source": [
    "Builds an edge index that specifies the edges in the graph $G_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c0345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edge_index(edges_up_to_t, address_to_local_id):\n",
    "    \"\"\"\n",
    "    Build edge index including ALL edges (OPTIMIZED VERSION).\n",
    "    \n",
    "    Args:\n",
    "        edges_up_to_t: DataFrame with edge data up to current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: edge_index [2, num_edges]\n",
    "    \"\"\"\n",
    "    # filter edges where both endpoints exist\n",
    "    valid_src = edges_up_to_t['input_address'].isin(address_to_local_id.keys())\n",
    "    valid_dst = edges_up_to_t['output_address'].isin(address_to_local_id.keys())\n",
    "    edges_valid = edges_up_to_t[valid_src & valid_dst]\n",
    "    \n",
    "    if len(edges_valid) == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "    \n",
    "    # map addresses to IDs using vectorized .map()\n",
    "    src_ids = edges_valid['input_address'].map(address_to_local_id).values\n",
    "    dst_ids = edges_valid['output_address'].map(address_to_local_id).values\n",
    "    \n",
    "    # stack into edge_index format [2, num_edges]\n",
    "    edge_index = np.stack([src_ids, dst_ids], axis=0)\n",
    "    \n",
    "    return torch.tensor(edge_index, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3567650",
   "metadata": {},
   "source": [
    "Helper method to prepare binary labels based on next time step data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd84864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_for_next_timestep(current_time_step, edges_df, node_labels_df, \n",
    "                                     active_addresses, address_to_local_id):\n",
    "    \"\"\"\n",
    "    Binary labels: 1 if node transacts with illicit node at t+1, else 0 (OPTIMIZED VERSION).\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        edges_df: DataFrame with all edge data (full dataset)\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "        active_addresses: array/list of addresses active up to current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: labels [num_nodes]\n",
    "    \"\"\"\n",
    "    num_active = len(active_addresses)\n",
    "    labels = torch.zeros(num_active, dtype=torch.long)\n",
    "    \n",
    "    # get edges at t+1\n",
    "    edges_next = edges_df[edges_df['Time step'] == current_time_step + 1]\n",
    "    if edges_next.empty:\n",
    "        return labels\n",
    "    \n",
    "    # get illicit addresses (as set for fast lookup)\n",
    "    illicit_addresses = set(node_labels_df[node_labels_df['class'] == 1]['address'].values)\n",
    "    \n",
    "    # vectorized operations to find nodes transacting with illicit\n",
    "    # find all source addresses where destination is illicit\n",
    "    illicit_dst_mask = edges_next['output_address'].isin(illicit_addresses)\n",
    "    src_to_illicit = set(edges_next.loc[illicit_dst_mask, 'input_address'].values)\n",
    "    \n",
    "    # find all destination addresses where source is illicit\n",
    "    illicit_src_mask = edges_next['input_address'].isin(illicit_addresses)\n",
    "    dst_from_illicit = set(edges_next.loc[illicit_src_mask, 'output_address'].values)\n",
    "    \n",
    "    # combine both sets\n",
    "    nodes_transacting_with_illicit = src_to_illicit | dst_from_illicit\n",
    "    \n",
    "    # label assignment\n",
    "    for addr in active_addresses:\n",
    "        if addr in address_to_local_id and addr in nodes_transacting_with_illicit:\n",
    "            local_id = address_to_local_id[addr]\n",
    "            labels[local_id] = 1\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e659a33",
   "metadata": {},
   "source": [
    "Helper to extract node classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68858b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_node_classes(active_addresses, address_to_local_id, node_labels_df):\n",
    "    \"\"\"\n",
    "    Extract node class labels (1=illicit, 2=licit, 3=unknown) (OPTIMIZED VERSION).\n",
    "    \n",
    "    Args:\n",
    "        active_addresses: array/list of addresses active up to current time step\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: node classes [num_nodes]\n",
    "    \"\"\"\n",
    "    num_active = len(active_addresses)\n",
    "    node_classes = np.full(num_active, 3)\n",
    "    \n",
    "    # create index for faster lookup\n",
    "    labels_indexed = node_labels_df.set_index('address')['class']\n",
    "    \n",
    "    # batch lookup\n",
    "    for addr in active_addresses:\n",
    "        if addr in labels_indexed.index:\n",
    "            local_id = address_to_local_id[addr]\n",
    "            node_classes[local_id] = labels_indexed.loc[addr]\n",
    "    \n",
    "    return torch.tensor(node_classes, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcad7d4",
   "metadata": {},
   "source": [
    "Main method that build a cummulative graph at time step t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c88656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cumulative_graph_at_timestep(current_time_step, nodes_df, edges_df, node_labels_df):\n",
    "    \"\"\"\n",
    "    Build cumulative graph up to time step t.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        nodes_df: DataFrame with all node data (full dataset)\n",
    "        edges_df: DataFrame with all edge data (full dataset)\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Data object, address_to_local_id dict)\n",
    "    \"\"\"\n",
    "    # get all nodes that appeared up to time t\n",
    "    nodes_up_to_t = nodes_df[nodes_df['Time step'] <= current_time_step].copy()\n",
    "    active_addresses = nodes_up_to_t['address'].unique()\n",
    "    address_to_local_id = {addr: idx for idx, addr in enumerate(active_addresses)}\n",
    "    \n",
    "    # get all edges up to time t\n",
    "    edges_up_to_t = edges_df[edges_df['Time step'] <= current_time_step]\n",
    "    \n",
    "    # build graph components\n",
    "    node_features = extract_node_features(nodes_up_to_t, active_addresses, address_to_local_id)\n",
    "    edge_index = build_edge_index(edges_up_to_t, address_to_local_id)\n",
    "    labels = create_labels_for_next_timestep(current_time_step, edges_df, node_labels_df, active_addresses, address_to_local_id)\n",
    "    node_classes = extract_node_classes(active_addresses, address_to_local_id, node_labels_df)\n",
    "    \n",
    "    # create PyG Data object\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        y=labels,\n",
    "        node_class=node_classes,\n",
    "        num_nodes=len(active_addresses)\n",
    "    )\n",
    "    \n",
    "    return data, address_to_local_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3c4b8",
   "metadata": {},
   "source": [
    "Build all the graphs for all the time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1055db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph for time step 1... Nodes: 34853, Edges: 66836, Positive: 0\n",
      "Building graph for time step 2... Nodes: 59236, Edges: 199129, Positive: 0\n",
      "Building graph for time step 3... Nodes: 78510, Edges: 264124, Positive: 4\n",
      "Building graph for time step 4... Nodes: 98707, Edges: 331393, Positive: 2\n",
      "Building graph for time step 5... Nodes: 120865, Edges: 399829, Positive: 2\n",
      "Building graph for time step 6... Nodes: 131985, Edges: 436559, Positive: 8\n",
      "Building graph for time step 7... Nodes: 152051, Edges: 492636, Positive: 6\n",
      "Building graph for time step 8... Nodes: 176366, Edges: 578493, Positive: 13\n",
      "Building graph for time step 9... Nodes: 194983, Edges: 638467, Positive: 4\n",
      "Building graph for time step 10... Nodes: 220639, Edges: 701970, Positive: 8\n",
      "Building graph for time step 11... Nodes: 239172, Edges: 763390, Positive: 0\n",
      "Building graph for time step 12... Nodes: 248071, Edges: 789186, Positive: 8\n",
      "Building graph for time step 13... Nodes: 268231, Edges: 838562, Positive: 4\n",
      "Building graph for time step 14... Nodes: 273241, Edges: 849218, Positive: 9\n",
      "Building graph for time step 15... Nodes: 285668, Edges: 935328, Positive: 10\n",
      "Building graph for time step 16... Nodes: 293042, Edges: 952871, Positive: 13\n",
      "Building graph for time step 17... Nodes: 305048, Edges: 980905, Positive: 7\n",
      "Building graph for time step 18... Nodes: 310031, Edges: 991937, Positive: 7\n",
      "Building graph for time step 19... Nodes: 319086, Edges: 1009347, Positive: 15\n",
      "Building graph for time step 20... Nodes: 345524, Edges: 1084995, Positive: 20\n",
      "Building graph for time step 21... Nodes: 375250, Edges: 1232114, Positive: 29\n",
      "Building graph for time step 22... Nodes: 396470, Edges: 1301819, Positive: 17\n",
      "Building graph for time step 23... Nodes: 408092, Edges: 1326365, Positive: 56\n",
      "Building graph for time step 24... Nodes: 423778, Edges: 1355964, Positive: 30\n",
      "Building graph for time step 25... Nodes: 435606, Edges: 1429696, Positive: 35\n",
      "Building graph for time step 26... Nodes: 448519, Edges: 1456557, Positive: 1\n",
      "Building graph for time step 27... Nodes: 454060, Edges: 1469020, Positive: 5\n",
      "Building graph for time step 28... Nodes: 458733, Edges: 1478952, Positive: 38\n",
      "Building graph for time step 29... Nodes: 474120, Edges: 1510474, Positive: 6\n",
      "Building graph for time step 30... Nodes: 482733, Edges: 1525398, Positive: 16\n",
      "Building graph for time step 31... Nodes: 495199, Edges: 1553241, Positive: 104\n",
      "Building graph for time step 32... Nodes: 509931, Edges: 1596832, Positive: 10\n",
      "Building graph for time step 33... Nodes: 521595, Edges: 1787166, Positive: 24\n",
      "Building graph for time step 34... Nodes: 530840, Edges: 1810073, Positive: 26\n",
      "Building graph for time step 35... Nodes: 552376, Edges: 1860027, Positive: 55\n",
      "Building graph for time step 36... Nodes: 582136, Edges: 1935978, Positive: 7\n",
      "Building graph for time step 37... Nodes: 595940, Edges: 1966199, Positive: 9\n",
      "Building graph for time step 38... Nodes: 610725, Edges: 1991574, Positive: 3\n",
      "Building graph for time step 39... Nodes: 620835, Edges: 2011116, Positive: 23\n",
      "Building graph for time step 40... Nodes: 646229, Edges: 2084318, Positive: 8\n",
      "Building graph for time step 41... Nodes: 667621, Edges: 2139238, Positive: 28\n",
      "Building graph for time step 42... Nodes: 697242, Edges: 2215839, Positive: 13\n",
      "Building graph for time step 43... Nodes: 720718, Edges: 2315829, Positive: 8\n",
      "Building graph for time step 44... Nodes: 738194, Edges: 2386988, Positive: 7\n",
      "Building graph for time step 45... Nodes: 761396, Edges: 2552766, Positive: 6\n",
      "Building graph for time step 46... Nodes: 775403, Edges: 2613128, Positive: 11\n",
      "Building graph for time step 47... Nodes: 795392, Edges: 2734525, Positive: 6\n",
      "Building graph for time step 48... Nodes: 811269, Edges: 2798924, Positive: 20\n",
      "\n",
      "Total graphs created: 48\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "time_steps = sorted(nodes['Time step'].unique())\n",
    "cumulative_graphs = []\n",
    "address_mappings = []\n",
    "\n",
    "for t in time_steps[:-1]:  # skip last timestep (no t+1 for labels)\n",
    "    print(f\"Building graph for time step {t}...\", end=\" \")\n",
    "    \n",
    "    graph_data, addr_mapping = build_cumulative_graph_at_timestep(\n",
    "        current_time_step=t,\n",
    "        nodes_df=nodes_with_labels,\n",
    "        edges_df=edges_with_edge_labels,\n",
    "        node_labels_df=node_labels\n",
    "    )\n",
    "    \n",
    "    cumulative_graphs.append(graph_data)\n",
    "    address_mappings.append(addr_mapping)\n",
    "    \n",
    "    num_positive = (graph_data.y == 1).sum().item()\n",
    "    print(f\"Nodes: {graph_data.num_nodes}, Edges: {graph_data.edge_index.shape[1]}, \"\n",
    "          f\"Positive: {num_positive}\")\n",
    "\n",
    "print(f\"\\nTotal graphs created: {len(cumulative_graphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0d934",
   "metadata": {},
   "source": [
    "Let's see per time step hoe many node transact with illict, licit, and unknown nodes. Maybe if we can classify the unknown better (classifiers in the paper get like 96% accuracy) we can have less sparse labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e598690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addresses: Illicit=14266, Licit=251088, Unknown=557588\n",
      "\n",
      "Time step 1: 66836 edges\n",
      "  Nodes transacting TO illicit: 59\n",
      "  Nodes transacting TO licit: 8437\n",
      "  Nodes transacting TO unknown: 14729\n",
      "  Edges TO illicit: 96\n",
      "  Edges TO licit: 31576\n",
      "  Edges TO unknown: 35164\n",
      "\n",
      "Time step 2: 132293 edges\n",
      "  Nodes transacting TO illicit: 54\n",
      "  Nodes transacting TO licit: 3073\n",
      "  Nodes transacting TO unknown: 6058\n",
      "  Edges TO illicit: 83\n",
      "  Edges TO licit: 98464\n",
      "  Edges TO unknown: 33746\n",
      "\n",
      "Time step 3: 64995 edges\n",
      "  Nodes transacting TO illicit: 35\n",
      "  Nodes transacting TO licit: 3389\n",
      "  Nodes transacting TO unknown: 10707\n",
      "  Edges TO illicit: 52\n",
      "  Edges TO licit: 9846\n",
      "  Edges TO unknown: 55097\n",
      "\n",
      "Time step 4: 67269 edges\n",
      "  Nodes transacting TO illicit: 211\n",
      "  Nodes transacting TO licit: 5777\n",
      "  Nodes transacting TO unknown: 8596\n",
      "  Edges TO illicit: 263\n",
      "  Edges TO licit: 13671\n",
      "  Edges TO unknown: 53335\n",
      "\n",
      "Time step 5: 68436 edges\n",
      "  Nodes transacting TO illicit: 39\n",
      "  Nodes transacting TO licit: 3845\n",
      "  Nodes transacting TO unknown: 10723\n",
      "  Edges TO illicit: 63\n",
      "  Edges TO licit: 15690\n",
      "  Edges TO unknown: 52683\n",
      "\n",
      "Time step 6: 36730 edges\n",
      "  Nodes transacting TO illicit: 10\n",
      "  Nodes transacting TO licit: 1778\n",
      "  Nodes transacting TO unknown: 6485\n",
      "  Edges TO illicit: 11\n",
      "  Edges TO licit: 3496\n",
      "  Edges TO unknown: 33223\n",
      "\n",
      "Time step 7: 56077 edges\n",
      "  Nodes transacting TO illicit: 339\n",
      "  Nodes transacting TO licit: 6335\n",
      "  Nodes transacting TO unknown: 13591\n",
      "  Edges TO illicit: 393\n",
      "  Edges TO licit: 12053\n",
      "  Edges TO unknown: 43631\n",
      "\n",
      "Time step 8: 85857 edges\n",
      "  Nodes transacting TO illicit: 250\n",
      "  Nodes transacting TO licit: 9090\n",
      "  Nodes transacting TO unknown: 7890\n",
      "  Edges TO illicit: 297\n",
      "  Edges TO licit: 44813\n",
      "  Edges TO unknown: 40747\n",
      "\n",
      "Time step 9: 59974 edges\n",
      "  Nodes transacting TO illicit: 595\n",
      "  Nodes transacting TO licit: 1921\n",
      "  Nodes transacting TO unknown: 11677\n",
      "  Edges TO illicit: 749\n",
      "  Edges TO licit: 5839\n",
      "  Edges TO unknown: 53386\n",
      "\n",
      "Time step 10: 63503 edges\n",
      "  Nodes transacting TO illicit: 67\n",
      "  Nodes transacting TO licit: 3718\n",
      "  Nodes transacting TO unknown: 7264\n",
      "  Edges TO illicit: 95\n",
      "  Edges TO licit: 18221\n",
      "  Edges TO unknown: 45187\n",
      "\n",
      "Time step 11: 61420 edges\n",
      "  Nodes transacting TO illicit: 304\n",
      "  Nodes transacting TO licit: 1563\n",
      "  Nodes transacting TO unknown: 5625\n",
      "  Edges TO illicit: 356\n",
      "  Edges TO licit: 40613\n",
      "  Edges TO unknown: 20451\n",
      "\n",
      "Time step 12: 25796 edges\n",
      "  Nodes transacting TO illicit: 48\n",
      "  Nodes transacting TO licit: 1507\n",
      "  Nodes transacting TO unknown: 2638\n",
      "  Edges TO illicit: 78\n",
      "  Edges TO licit: 9012\n",
      "  Edges TO unknown: 16706\n",
      "\n",
      "Time step 13: 49376 edges\n",
      "  Nodes transacting TO illicit: 546\n",
      "  Nodes transacting TO licit: 1948\n",
      "  Nodes transacting TO unknown: 6503\n",
      "  Edges TO illicit: 695\n",
      "  Edges TO licit: 10603\n",
      "  Edges TO unknown: 38078\n",
      "\n",
      "Time step 14: 10656 edges\n",
      "  Nodes transacting TO illicit: 110\n",
      "  Nodes transacting TO licit: 1456\n",
      "  Nodes transacting TO unknown: 2229\n",
      "  Edges TO illicit: 130\n",
      "  Edges TO licit: 4277\n",
      "  Edges TO unknown: 6249\n",
      "\n",
      "Time step 15: 86110 edges\n",
      "  Nodes transacting TO illicit: 313\n",
      "  Nodes transacting TO licit: 1719\n",
      "  Nodes transacting TO unknown: 3223\n",
      "  Edges TO illicit: 358\n",
      "  Edges TO licit: 65917\n",
      "  Edges TO unknown: 19835\n",
      "\n",
      "Time step 16: 17543 edges\n",
      "  Nodes transacting TO illicit: 266\n",
      "  Nodes transacting TO licit: 1515\n",
      "  Nodes transacting TO unknown: 2896\n",
      "  Edges TO illicit: 333\n",
      "  Edges TO licit: 5936\n",
      "  Edges TO unknown: 11274\n",
      "\n",
      "Time step 17: 28034 edges\n",
      "  Nodes transacting TO illicit: 214\n",
      "  Nodes transacting TO licit: 2550\n",
      "  Nodes transacting TO unknown: 4459\n",
      "  Edges TO illicit: 283\n",
      "  Edges TO licit: 9228\n",
      "  Edges TO unknown: 18523\n",
      "\n",
      "Time step 18: 11032 edges\n",
      "  Nodes transacting TO illicit: 139\n",
      "  Nodes transacting TO licit: 1383\n",
      "  Nodes transacting TO unknown: 2184\n",
      "  Edges TO illicit: 164\n",
      "  Edges TO licit: 4287\n",
      "  Edges TO unknown: 6581\n",
      "\n",
      "Time step 19: 17410 edges\n",
      "  Nodes transacting TO illicit: 211\n",
      "  Nodes transacting TO licit: 2350\n",
      "  Nodes transacting TO unknown: 3751\n",
      "  Edges TO illicit: 266\n",
      "  Edges TO licit: 5622\n",
      "  Edges TO unknown: 11522\n",
      "\n",
      "Time step 20: 75648 edges\n",
      "  Nodes transacting TO illicit: 558\n",
      "  Nodes transacting TO licit: 2640\n",
      "  Nodes transacting TO unknown: 7143\n",
      "  Edges TO illicit: 803\n",
      "  Edges TO licit: 21302\n",
      "  Edges TO unknown: 53543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "illicit_addrs = set(node_labels[node_labels['class'] == 1]['address'].values)\n",
    "licit_addrs = set(node_labels[node_labels['class'] == 2]['address'].values)\n",
    "unknown_addrs = set(node_labels[node_labels['class'] == 3]['address'].values)\n",
    "\n",
    "print(f\"Total addresses: Illicit={len(illicit_addrs)}, Licit={len(licit_addrs)}, Unknown={len(unknown_addrs)}\\n\")\n",
    "\n",
    "for t in sorted(edges_with_edge_labels['Time step'].unique())[:20]:  # First 20 time steps\n",
    "    edges_t = edges_with_edge_labels[edges_with_edge_labels['Time step'] == t]\n",
    "    \n",
    "    # categorize edges by destination node class\n",
    "    edges_to_illicit = edges_t[edges_t['output_address'].isin(illicit_addrs)]\n",
    "    edges_to_licit = edges_t[edges_t['output_address'].isin(licit_addrs)]\n",
    "    edges_to_unknown = edges_t[edges_t['output_address'].isin(unknown_addrs)]\n",
    "    \n",
    "    # count unique source nodes transacting with each class\n",
    "    nodes_transacting_to_illicit = edges_to_illicit['input_address'].nunique()\n",
    "    nodes_transacting_to_licit = edges_to_licit['input_address'].nunique()\n",
    "    nodes_transacting_to_unknown = edges_to_unknown['input_address'].nunique()\n",
    "    \n",
    "    print(f\"Time step {t}: {len(edges_t)} edges\")\n",
    "    print(f\"  Nodes transacting TO illicit: {nodes_transacting_to_illicit}\")\n",
    "    print(f\"  Nodes transacting TO licit: {nodes_transacting_to_licit}\")\n",
    "    print(f\"  Nodes transacting TO unknown: {nodes_transacting_to_unknown}\")\n",
    "    print(f\"  Edges TO illicit: {len(edges_to_illicit)}\")\n",
    "    print(f\"  Edges TO licit: {len(edges_to_licit)}\")\n",
    "    print(f\"  Edges TO unknown: {len(edges_to_unknown)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593461e",
   "metadata": {},
   "source": [
    "This is weird. Ok i suspect teh issue is that nodes that appear at some time step t mostly have only transactions at the same time step, and dont transact in later timesteps again. let's check how many nodes transact at timesteps other than the one they were created at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13940f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique addresses: 822,942\n",
      "\n",
      "Nodes that transact:\n",
      "  Only at creation time step: 761,455 (92.5%)\n",
      "  At other time steps (after creation): 61,487 (7.5%)\n"
     ]
    }
   ],
   "source": [
    "# for each address, find first appearance and all appearances\n",
    "address_first_appearance = nodes.groupby('address')['Time step'].min()\n",
    "address_all_appearances = nodes.groupby('address')['Time step'].apply(set)\n",
    "\n",
    "# count how many appear after their first time step\n",
    "transacts_after_creation = 0\n",
    "only_at_creation = 0\n",
    "\n",
    "for addr in address_first_appearance.index:\n",
    "    first_ts = address_first_appearance[addr]\n",
    "    all_ts = address_all_appearances[addr]\n",
    "    \n",
    "    # check if node appears at any time step other than first\n",
    "    if len(all_ts) > 1 or (len(all_ts) == 1 and first_ts not in all_ts):\n",
    "        transacts_after_creation += 1\n",
    "    else:\n",
    "        only_at_creation += 1\n",
    "\n",
    "total = len(address_first_appearance)\n",
    "\n",
    "print(f\"Total unique addresses: {total:,}\")\n",
    "print(f\"\\nNodes that transact:\")\n",
    "print(f\"  Only at creation time step: {only_at_creation:,} ({100*only_at_creation/total:.1f}%)\")\n",
    "print(f\"  At other time steps (after creation): {transacts_after_creation:,} ({100*transacts_after_creation/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5558a111",
   "metadata": {},
   "source": [
    "That explains it. Now lets see how does it look for some node wrt to illict transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1801499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in graph at t=3: 78510\n",
      "Nodes appearing at t=4: 21030\n",
      "  Brand new at t=4: 20197\n",
      "  Reappearing at t=4: 833\n",
      "\n",
      "Nodes transacting with illicit at t=4: 273\n",
      "  Existed in graph at t=3: 4 ← should match positive labels\n",
      "  Brand new nodes at t=4: 269 ← cannot predict these\n"
     ]
    }
   ],
   "source": [
    "t = 3\n",
    "\n",
    "# Nodes in graph at t=3\n",
    "nodes_up_to_t = nodes_with_labels[nodes_with_labels['Time step'] <= t]\n",
    "active_at_t = set(nodes_up_to_t['address'].unique())\n",
    "print(f\"Nodes in graph at t={t}: {len(active_at_t)}\")\n",
    "\n",
    "# nodes that appear at t=4\n",
    "nodes_at_t_plus_1 = nodes_with_labels[nodes_with_labels['Time step'] == t + 1]\n",
    "nodes_appearing_at_t_plus_1 = set(nodes_at_t_plus_1['address'].unique())\n",
    "print(f\"Nodes appearing at t={t+1}: {len(nodes_appearing_at_t_plus_1)}\")\n",
    "\n",
    "# check how many of t=4 nodes are brand new vs. reappearing\n",
    "new_nodes_at_t_plus_1 = nodes_appearing_at_t_plus_1 - active_at_t\n",
    "reappearing_nodes_at_t_plus_1 = nodes_appearing_at_t_plus_1 & active_at_t\n",
    "print(f\"  Brand new at t={t+1}: {len(new_nodes_at_t_plus_1)}\")\n",
    "print(f\"  Reappearing at t={t+1}: {len(reappearing_nodes_at_t_plus_1)}\")\n",
    "\n",
    "# check who transacts with illicit at t=4\n",
    "edges_at_t_plus_1 = edges_with_edge_labels[edges_with_edge_labels['Time step'] == t + 1]\n",
    "illicit_addrs = set(node_labels[node_labels['class'] == 1]['address'].values)\n",
    "\n",
    "edges_to_illicit = edges_at_t_plus_1[edges_at_t_plus_1['output_address'].isin(illicit_addrs)]\n",
    "edges_from_illicit = edges_at_t_plus_1[edges_at_t_plus_1['input_address'].isin(illicit_addrs)]\n",
    "\n",
    "nodes_transacting_with_illicit = set(edges_to_illicit['input_address'].values) | set(edges_from_illicit['output_address'].values)\n",
    "print(f\"\\nNodes transacting with illicit at t={t+1}: {len(nodes_transacting_with_illicit)}\")\n",
    "\n",
    "# ff these, check how many existed at t=3\n",
    "existing_transactors = nodes_transacting_with_illicit & active_at_t\n",
    "new_transactors = nodes_transacting_with_illicit - active_at_t\n",
    "\n",
    "print(f\"  Existed in graph at t={t}: {len(existing_transactors)} ← should match positive labels\")\n",
    "print(f\"  Brand new nodes at t={t+1}: {len(new_transactors)} ← cannot predict these\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2cbc5",
   "metadata": {},
   "source": [
    "Maybe it's better to reframe the problem as - \"Will an illicit node appear in my neighborhood in at most k time steps in the future?\" and use graph structure at time t to predict emergence at t+1, not necessarily the transactions (edges). Maybe we should go like - if any of the nodes within a walk of 5 (k) steps will connect to an illict node at next time step, then we say label 1? And then not only look at the next time step but multiple time-steps (all of them or some window, lets say $[t+1, t+k]$? So it's like if we are in proximit of the future illict activity, then label is one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56176fc",
   "metadata": {},
   "source": [
    "NOTE: so like if a node a has an edge at next time step or now or in the past (t+1) or a walk of some length k that brings it to a node that makes a transaction to an illict node (has an edge) at t+1 or later time steps, we mark it as 1 - in future the neighbourhood will have illlict nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "onrci273pb",
   "metadata": {},
   "source": [
    "NOTE: so like if a node a has an edge at next time step or now or in the past (t+1) or a walk of some length k that brings it to a node that makes a transaction to an illict node (has an edge) at t+1 or later time steps, we mark it as 1 - in future the neighbourhood will have illlict nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0np9ql14nnxo",
   "metadata": {},
   "source": [
    "## K-Hop Neighborhood + Multi-Horizon Labeling\n",
    "\n",
    "The issue with direct prediction is that 92.5% of nodes only appear once, making it impossible to predict future illicit transactions for most nodes. We reframe the problem:\n",
    "\n",
    "**New Task**: At time step t, predict if **any node in a node's k-hop undirected neighborhood** will transact with illicit nodes in the **next p time steps**.\n",
    "\n",
    "This gives us:\n",
    "- More positive labels (neighborhood aggregates signal)\n",
    "- Early warning system (detect proximity to future illicit activity)\n",
    "- Tunable hyperparameters: `k_hops` (neighborhood radius) and `horizon` (how many future time steps)\n",
    "\n",
    "Default values: `k_hops=2`, `horizon=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ya9vby2mrif",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xow9ogxkpx",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_undirected_adjacency_sparse(edge_index, num_nodes):\n",
    "    \"\"\"\n",
    "    Build symmetric sparse adjacency matrix from edge_index.\n",
    "    \n",
    "    Args:\n",
    "        edge_index: torch.Tensor [2, num_edges], directed edge list\n",
    "        num_nodes: int, total number of nodes\n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: symmetric adjacency matrix [num_nodes, num_nodes]\n",
    "    \"\"\"\n",
    "    if edge_index.shape[1] == 0:\n",
    "        return csr_matrix((num_nodes, num_nodes))\n",
    "    \n",
    "    # convert to numpy\n",
    "    edge_index_np = edge_index.cpu().numpy()\n",
    "    \n",
    "    # create directed edges\n",
    "    src = edge_index_np[0]\n",
    "    dst = edge_index_np[1]\n",
    "    \n",
    "    # add reverse edges for undirected graph \n",
    "    # NOTE: we want to calculate the k-hop distance regardless of node direction for now???\n",
    "    all_src = np.concatenate([src, dst])\n",
    "    all_dst = np.concatenate([dst, src])\n",
    "    \n",
    "    # create sparse matrix (values are 1s for adjacency)\n",
    "    data = np.ones(len(all_src), dtype=np.float32)\n",
    "    adjacency_matrix = csr_matrix((data, (all_src, all_dst)), shape=(num_nodes, num_nodes))\n",
    "    \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lk9i8pgxi9j",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_k_hop_reachability(adjacency_matrix, k_hops):\n",
    "    \"\"\"\n",
    "    Compute k-hop reachability matrix using sparse matrix powers.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: scipy.sparse.csr_matrix, adjacency matrix\n",
    "        k_hops: int, neighborhood radius\n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: boolean matrix where [i,j]=1 if j is reachable from i in ≤k hops\n",
    "    \"\"\"\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # start with identity (0-hop: each node reaches itself)\n",
    "    reachability = sp.eye(num_nodes, format='csr')\n",
    "    \n",
    "    # current power of adjacency matrix\n",
    "    current_power = adjacency_matrix.copy()\n",
    "    \n",
    "    # add A + A^2 + ... + A^k\n",
    "    # this will give us esges whenever we can reach the other matrix in a k-hop walk\n",
    "    for hop in range(1, k_hops + 1):\n",
    "        if hop > 1:\n",
    "            current_power = current_power @ adjacency_matrix\n",
    "        reachability = reachability + current_power\n",
    "    \n",
    "    # convert to boolean matrix\n",
    "    reachability = (reachability > 0).astype(np.float32)\n",
    "    \n",
    "    return reachability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a642a",
   "metadata": {},
   "source": [
    "### !!! **NOTE** / **TODO** !!!\n",
    "\n",
    " Maybe instead of creating 1 and 0 binary labels we would want to have the labels be the distance to the closest node within the k-hop distance that will have an illict transaction in the future? so like 0 if its this node, 1 if the neighbour, 2 if 2nd neighbor? Maybe even not limit it to the k-hop and just calculate that for every node in the graph?I think this would be more precise??? Then it becomes a regression problem - Franek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9o80l0dxgpi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_k_hop_multi_horizon(current_time_step, edges_df, node_labels_df, \n",
    "                                       active_addresses, address_to_local_id,\n",
    "                                       edge_index, num_nodes, \n",
    "                                       k_hops=2, horizon=3):\n",
    "    \"\"\"\n",
    "    Binary labels with k-hop neighborhood + multi-horizon prediction.\n",
    "    \n",
    "    Label = 1 if ANY node in the k-hop neighborhood transacts with illicit \n",
    "    in time steps [t+1, t+2, ..., t+horizon]\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        edges_df: DataFrame with all edge data\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "        active_addresses: array/list of addresses active up to t\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "        edge_index: torch.Tensor [2, num_edges], graph structure at time t\n",
    "        num_nodes: int, number of nodes in graph\n",
    "        k_hops: int, neighborhood radius (default=2)\n",
    "        horizon: int, number of future time steps to check (default=3)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: labels [num_nodes]\n",
    "    \"\"\"\n",
    "\n",
    "    # NOTE / TODO: maybe instead of creating 1 and 0 labels we would \n",
    "    # want to have the labels be the distance to the closest node\n",
    "    # within the k-hop distance that will have an illict transaction in the future?\n",
    "    # so like 0 if its this node, 1 if the neighbour, 2 if 2nd neighbor?\n",
    "    # maybe even not limit it to the k-hop and just calculate that for every node in the graph?\n",
    "    # I think this would be more precise??? - Franek\n",
    "\n",
    "    labels = torch.zeros(num_nodes, dtype=torch.long)\n",
    "    \n",
    "    # build undirected adjacency matrix\n",
    "    adjacency_matrix = build_undirected_adjacency_sparse(edge_index, num_nodes)\n",
    "    \n",
    "    # compute k-hop reachability\n",
    "    reachability = compute_k_hop_reachability(adjacency_matrix, k_hops)\n",
    "    \n",
    "    # get illicit addresses\n",
    "    illicit_addresses = set(node_labels_df[node_labels_df['class'] == 1]['address'].values)\n",
    "    \n",
    "    # collect all nodes that transact with illicit in this set\n",
    "    # So the nodes in [t+1, ..., t+horizon]\n",
    "    nodes_transacting_with_illicit_in_horizon = set()\n",
    "\n",
    "    # le loop\n",
    "    for future_t in range(current_time_step + 1, current_time_step + horizon + 1):\n",
    "\n",
    "        # get edges in the future time step\n",
    "        edges_future = edges_df[edges_df['Time step'] == future_t]\n",
    "        if edges_future.empty:\n",
    "            continue\n",
    "        \n",
    "        # find tarnsaction edges that go to illict addresses\n",
    "        illicit_dst_mask = edges_future['output_address'].isin(illicit_addresses)\n",
    "\n",
    "        # get the input addresses of thos edges\n",
    "        src_to_illicit = set(edges_future.loc[illicit_dst_mask, 'input_address'].values)\n",
    "        \n",
    "        # find transaction edges that come from illict addresses\n",
    "        illicit_src_mask = edges_future['input_address'].isin(illicit_addresses)\n",
    "\n",
    "        # get the output addresses of those transactions\n",
    "        dst_from_illicit = set(edges_future.loc[illicit_src_mask, 'output_address'].values)\n",
    "        \n",
    "        # collect addresses of nodes that tarnsact with illict nodes inthe future time step\n",
    "        nodes_transacting_with_illicit_in_horizon.update(src_to_illicit | dst_from_illicit)\n",
    "    \n",
    "    # map these addresses to local IDs (only those in current graph)\n",
    "    future_illicit_transactor_ids = []\n",
    "    for addr in nodes_transacting_with_illicit_in_horizon:\n",
    "        # if the address is in the current geaph (until time t) keep the info that it will transact with an illict node\n",
    "        if addr in address_to_local_id:\n",
    "            future_illicit_transactor_ids.append(address_to_local_id[addr])\n",
    "    \n",
    "    if len(future_illicit_transactor_ids) == 0:\n",
    "        return labels\n",
    "    \n",
    "    # for each node, check if any of its k-hop neighbors will transact with illicit\n",
    "    future_illicit_transactor_ids = np.array(future_illicit_transactor_ids)\n",
    "    \n",
    "    # extract reachability to these specific nodes\n",
    "    # reachability[i, j] = 1 if node j is reachable from node i\n",
    "    reachability_to_illicit_transactors = reachability[:, future_illicit_transactor_ids]\n",
    "    \n",
    "    # if any illict neighbor is reachable, label = 1\n",
    "    has_illicit_in_neighborhood = (reachability_to_illicit_transactors.sum(axis=1) > 0).A1\n",
    "    \n",
    "    labels = torch.tensor(has_illicit_in_neighborhood, dtype=torch.long)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kw0pqpr9lo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cumulative_graph_at_timestep_khop(current_time_step, nodes_df, edges_df, node_labels_df,\n",
    "                                             k_hops=2, horizon=3):\n",
    "    \"\"\"\n",
    "    Build cumulative graph with k-hop + multi-horizon labeling.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        nodes_df: DataFrame with all node data\n",
    "        edges_df: DataFrame with all edge data\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "        k_hops: int, neighborhood radius (default=2)\n",
    "        horizon: int, future time steps to check (default=3)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Data object, address_to_local_id dict)\n",
    "    \"\"\"\n",
    "    # get all nodes that appeared up to time t\n",
    "    nodes_up_to_t = nodes_df[nodes_df['Time step'] <= current_time_step].copy()\n",
    "    active_addresses = nodes_up_to_t['address'].unique()\n",
    "    address_to_local_id = {addr: idx for idx, addr in enumerate(active_addresses)}\n",
    "    \n",
    "    # get all edges up to time t\n",
    "    edges_up_to_t = edges_df[edges_df['Time step'] <= current_time_step]\n",
    "    \n",
    "    # build graph components\n",
    "    node_features = extract_node_features(nodes_up_to_t, active_addresses, address_to_local_id)\n",
    "    edge_index = build_edge_index(edges_up_to_t, address_to_local_id)\n",
    "    num_nodes = len(active_addresses)\n",
    "    \n",
    "    # k-hop + multi-horizon labels\n",
    "    labels = create_labels_k_hop_multi_horizon(\n",
    "        current_time_step=current_time_step,\n",
    "        edges_df=edges_df,\n",
    "        node_labels_df=node_labels_df,\n",
    "        active_addresses=active_addresses,\n",
    "        address_to_local_id=address_to_local_id, # NOTE: those only contain until time t, so all good\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        k_hops=k_hops,\n",
    "        horizon=horizon\n",
    "    )\n",
    "    \n",
    "    node_classes = extract_node_classes(active_addresses, address_to_local_id, node_labels_df)\n",
    "    \n",
    "    # create PyG Data object\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        y=labels,\n",
    "        node_class=node_classes,\n",
    "        num_nodes=num_nodes\n",
    "    )\n",
    "    \n",
    "    return data, address_to_local_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b98yvnvs8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graphs with k_hops=2, horizon=3\n",
      "\n",
      "Building graph for time step 1... Nodes: 34853, Edges: 66836, Positive: 1196\n",
      "Building graph for time step 2... Nodes: 59236, Edges: 199129, Positive: 1684\n",
      "Building graph for time step 3... Nodes: 78510, Edges: 264124, Positive: 2810\n",
      "Building graph for time step 4... Nodes: 98707, Edges: 331393, Positive: 3411\n",
      "Building graph for time step 5... Nodes: 120865, Edges: 399829, Positive: 2421\n",
      "Building graph for time step 6... Nodes: 131985, Edges: 436559, Positive: 2427\n",
      "Building graph for time step 7... Nodes: 152051, Edges: 492636, Positive: 8367\n",
      "Building graph for time step 8... Nodes: 176366, Edges: 578493, Positive: 9638\n",
      "Building graph for time step 9... Nodes: 194983, Edges: 638467, Positive: 11190\n",
      "Building graph for time step 10... Nodes: 220639, Edges: 701970, Positive: 5192\n",
      "Building graph for time step 11... Nodes: 239172, Edges: 763390, Positive: 686\n",
      "Building graph for time step 12... Nodes: 248071, Edges: 789186, Positive: 10548\n",
      "Building graph for time step 13... Nodes: 268231, Edges: 838562, Positive: 3610\n",
      "Building graph for time step 14... Nodes: 273241, Edges: 849218, Positive: 14256\n",
      "Building graph for time step 15... Nodes: 285668, Edges: 935328, Positive: 13910\n",
      "Building graph for time step 16... Nodes: 293042, Edges: 952871, Positive: 14487\n",
      "Building graph for time step 17... Nodes: 305048, Edges: 980905, Positive: 11066\n",
      "Building graph for time step 18... Nodes: 310031, Edges: 991937, Positive: 22400\n",
      "Building graph for time step 19... Nodes: 319086, Edges: 1009347, Positive: 44245\n",
      "Building graph for time step 20... Nodes: 345524, Edges: 1084995, Positive: 55536\n",
      "Building graph for time step 21... Nodes: 375250, Edges: 1232114, Positive: 66153\n",
      "Building graph for time step 22... Nodes: 396470, Edges: 1301819, Positive: 70579\n",
      "Building graph for time step 23... Nodes: 408092, Edges: 1326365, Positive: 84574\n",
      "Building graph for time step 24... Nodes: 423778, Edges: 1355964, Positive: 61129\n",
      "Building graph for time step 25... Nodes: 435606, Edges: 1429696, Positive: 35315\n",
      "Building graph for time step 26... Nodes: 448519, Edges: 1456557, Positive: 37561\n",
      "Building graph for time step 27... Nodes: 454060, Edges: 1469020, Positive: 38770\n",
      "Building graph for time step 28... Nodes: 458733, Edges: 1478952, Positive: 32852\n",
      "Building graph for time step 29... Nodes: 474120, Edges: 1510474, Positive: 101371\n",
      "Building graph for time step 30... Nodes: 482733, Edges: 1525398, Positive: 103617\n",
      "Building graph for time step 31... Nodes: 495199, Edges: 1553241, Positive: 105106\n",
      "Building graph for time step 32... Nodes: 509931, Edges: 1596832, Positive: 48910\n",
      "Building graph for time step 33... Nodes: 521595, Edges: 1787166, Positive: 82455\n",
      "Building graph for time step 34... Nodes: 530840, Edges: 1810073, Positive: 69215\n",
      "Building graph for time step 35... Nodes: 552376, Edges: 1860027, Positive: 66749\n",
      "Building graph for time step 36... Nodes: 582136, Edges: 1935978, Positive: 20631\n",
      "Building graph for time step 37... Nodes: 595940, Edges: 1966199, Positive: 56119\n",
      "Building graph for time step 38... Nodes: 610725, Edges: 1991574, Positive: 57524\n",
      "Building graph for time step 39... Nodes: 620835, Edges: 2011116, Positive: 68643\n",
      "Building graph for time step 40... Nodes: 646229, Edges: 2084318, Positive: 48782\n",
      "Building graph for time step 41... Nodes: 667621, Edges: 2139238, Positive: 53894\n",
      "Building graph for time step 42... Nodes: 697242, Edges: 2215839, Positive: 50836\n",
      "Building graph for time step 43... Nodes: 720718, Edges: 2315829, Positive: 18957\n",
      "Building graph for time step 44... Nodes: 738194, Edges: 2386988, Positive: 32732\n",
      "Building graph for time step 45... Nodes: 761396, Edges: 2552766, Positive: 27219\n",
      "Building graph for time step 46... Nodes: 775403, Edges: 2613128, Positive: 31336\n",
      "\n",
      "Total graphs created: 46\n"
     ]
    }
   ],
   "source": [
    "# Build all graphs with k-hop + multi-horizon labeling\n",
    "# Hyperparameters\n",
    "K_HOPS = 2\n",
    "HORIZON = 3\n",
    "\n",
    "cumulative_graphs_khop = []\n",
    "address_mappings_khop = []\n",
    "\n",
    "print(f\"Building graphs with k_hops={K_HOPS}, horizon={HORIZON}\\n\")\n",
    "\n",
    "for t in time_steps[:-HORIZON]:  # need horizon future time steps\n",
    "    print(f\"Building graph for time step {t}...\", end=\" \")\n",
    "    \n",
    "    graph_data, addr_mapping = build_cumulative_graph_at_timestep_khop(\n",
    "        current_time_step=t,\n",
    "        nodes_df=nodes_with_labels,\n",
    "        edges_df=edges_with_edge_labels,\n",
    "        node_labels_df=node_labels,\n",
    "        k_hops=K_HOPS,\n",
    "        horizon=HORIZON\n",
    "    )\n",
    "    \n",
    "    cumulative_graphs_khop.append(graph_data)\n",
    "    address_mappings_khop.append(addr_mapping)\n",
    "    \n",
    "    num_positive = (graph_data.y == 1).sum().item()\n",
    "    print(f\"Nodes: {graph_data.num_nodes}, Edges: {graph_data.edge_index.shape[1]}, \"\n",
    "          f\"Positive: {num_positive}\")\n",
    "\n",
    "print(f\"\\nTotal graphs created: {len(cumulative_graphs_khop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca39af",
   "metadata": {},
   "source": [
    "Now this is what im talking abt - this is much better :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe6eb3",
   "metadata": {},
   "source": [
    "---\n",
    "#### TODOs for graph building:\n",
    "- sanity check on the code, maybe id print the reachability matrix out just to see shit makes sense etc (well ist huge but like a chunk of it or sth)\n",
    "- visualize the graphs obtained in this way\n",
    "- consider framing it as a regression problem (i think it's better) as explained in the NOTE / TODO slightly above.\n",
    "\n",
    "---\n",
    "#### Next steps:\n",
    "- train a GCN and EVolveGCn baselines\n",
    "- figure out how do use a TGN\n",
    "- do we ditch the discrete time steps and use block indices as time stamps for like eent absed type thing?\n",
    "- or maybe make the windows smaller based on the block indices? Sth to think abt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686e60e",
   "metadata": {},
   "source": [
    "## K-Hop but make it a regression approach (the one from NOTE / TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b61f2",
   "metadata": {},
   "source": [
    "Helper for calculatig distances in the k-hop range to any other node in he graph (assuming undirected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ef078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(adjacency_matrix, k_hops):\n",
    "    \"\"\"\n",
    "    Compute a distance matrix from any node in the graph to any other node.\n",
    "    \n",
    "    Args:\n",
    "        adjacency_matrix: scipy.sparse.csr_matrix, adjacency matrix\n",
    "        k_hops: int, neighborhood radius\n",
    "    \n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: boolean matrix where [i,j]=1 if j is reachable from i in ≤k hops\n",
    "    \"\"\"\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    \n",
    "    # start with identity (0-hop: each node reaches itself)\n",
    "    visited = sp.eye(num_nodes, format='csr')\n",
    "    distances = sp.csr_matrix((num_nodes, num_nodes))\n",
    "    \n",
    "    # current power of adjacency matrix\n",
    "    current_power = adjacency_matrix.copy()\n",
    "    \n",
    "    # add A + A^2 + ... + A^k\n",
    "    # this will give us edges whenever we can reach the other matrix in a k-hop walk\n",
    "    for hop in range(1, k_hops + 1):\n",
    "        if hop > 1:\n",
    "            current_power = current_power @ adjacency_matrix\n",
    "\n",
    "        # onlye keep the non visited values\n",
    "        mask = current_power.multiply(1 - visited)\n",
    "\n",
    "        # set distance matrix values to hop\n",
    "        mask = mask.sign() * hop\n",
    "\n",
    "        # update visited matrix\n",
    "        visited = (visited + current_power).minimum(1)\n",
    "\n",
    "        # update distances\n",
    "        distances = distances + mask\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49434aa1",
   "metadata": {},
   "source": [
    "#### Helper for calculating distance based labels\n",
    "**IMPORTANT NOTE**: if no illict transaction within k_hop distance limit, the labels is set to k-hops + 1!!!! \n",
    "(Would be weird to set it to -1 for regression, I guess we could then add a linear layer on top of our GCN and then just have it map to respective outputs but scre that for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_k_hop_distance_multi_horizon(current_time_step, edges_df, node_labels_df, \n",
    "                                       active_addresses, address_to_local_id,\n",
    "                                       edge_index, num_nodes, \n",
    "                                       k_hops=2, horizon=3):\n",
    "    \"\"\"\n",
    "    Distance-based labels with k-hop neighborhood + multi-horizon prediction.\n",
    "    \n",
    "    Label = distance to the closest node in k-hop neighborhood that transacts with illicit \n",
    "    in time steps [t+1, t+2, ..., t+horizon]. If no such node exists, label = k_hops + 1.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        edges_df: DataFrame with all edge data\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "        active_addresses: array/list of addresses active up to t\n",
    "        address_to_local_id: dict mapping address -> local node ID\n",
    "        edge_index: torch.Tensor [2, num_edges], graph structure at time t\n",
    "        num_nodes: int, number of nodes in graph\n",
    "        k_hops: int, neighborhood radius (default=2)\n",
    "        horizon: int, number of future time steps to check (default=3)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: labels [num_nodes] in range [0, k_hops + 1]\n",
    "            - 0: node itself will transact with illicit\n",
    "            - 1, 2, ..., k_hops: distance to nearest future illicit transactor\n",
    "            - k_hops + 1: no illicit activity in k-hop neighborhood\n",
    "    \"\"\"\n",
    "    \n",
    "    # build undirected adjacency matrix\n",
    "    adjacency_matrix = build_undirected_adjacency_sparse(edge_index, num_nodes)\n",
    "    \n",
    "    # compute distances to neighbours within k-hops\n",
    "    distances = compute_distance_matrix(adjacency_matrix, k_hops)\n",
    "    \n",
    "    # get illicit addresses\n",
    "    illicit_addresses = set(node_labels_df[node_labels_df['class'] == 1]['address'].values)\n",
    "    \n",
    "    # collect all nodes that transact with illicit in this set\n",
    "    # So the nodes in [t+1, ..., t+horizon]\n",
    "    nodes_transacting_with_illicit_in_horizon = set()\n",
    "\n",
    "    # le loop\n",
    "    for future_t in range(current_time_step + 1, current_time_step + horizon + 1):\n",
    "\n",
    "        # get edges in the future time step\n",
    "        edges_future = edges_df[edges_df['Time step'] == future_t]\n",
    "        if edges_future.empty:\n",
    "            continue\n",
    "        \n",
    "        # find tarnsaction edges that go to illict addresses\n",
    "        illicit_dst_mask = edges_future['output_address'].isin(illicit_addresses)\n",
    "\n",
    "        # get the input addresses of thos edges\n",
    "        src_to_illicit = set(edges_future.loc[illicit_dst_mask, 'input_address'].values)\n",
    "        \n",
    "        # find transaction edges that come from illict addresses\n",
    "        illicit_src_mask = edges_future['input_address'].isin(illicit_addresses)\n",
    "\n",
    "        # get the output addresses of those transactions\n",
    "        dst_from_illicit = set(edges_future.loc[illicit_src_mask, 'output_address'].values)\n",
    "        \n",
    "        # collect addresses of nodes that tarnsact with illict nodes inthe future time step\n",
    "        nodes_transacting_with_illicit_in_horizon.update(src_to_illicit | dst_from_illicit)\n",
    "    \n",
    "    # map these addresses to local IDs (only those in current graph)\n",
    "    future_illicit_transactor_ids = []\n",
    "    for addr in nodes_transacting_with_illicit_in_horizon:\n",
    "        # if the address is in the current geaph (until time t) keep the info that it will transact with an illict node\n",
    "        if addr in address_to_local_id:\n",
    "            future_illicit_transactor_ids.append(address_to_local_id[addr])\n",
    "    \n",
    "    # Initialize all labels to k_hops + 1 (no illicit in k-hop neighborhood)\n",
    "    labels = np.full(num_nodes, k_hops + 1, dtype=int)\n",
    "    \n",
    "    if len(future_illicit_transactor_ids) == 0:\n",
    "        return torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    # for each node, check if any of its k-hop neighbors will transact with illicit\n",
    "    future_illicit_transactor_ids = np.array(future_illicit_transactor_ids)\n",
    "\n",
    "    # extract distances to these specific nodes\n",
    "    # distances[i, j] = distance if node j is reachable from node i within k hops\n",
    "    distances_to_illicit = distances[:, future_illicit_transactor_ids].toarray()\n",
    "\n",
    "    # Create set for fast lookup\n",
    "    future_illicit_set = set(future_illicit_transactor_ids)\n",
    "\n",
    "    # Compute labels for each node\n",
    "    for i in range(num_nodes):\n",
    "        if i in future_illicit_set:\n",
    "            # this node itself will transact with illicit\n",
    "            labels[i] = 0\n",
    "        else:\n",
    "            # otherwise find minimum non-zero distance\n",
    "            row_distances = distances_to_illicit[i, :]\n",
    "            valid_distances = row_distances[row_distances > 0]\n",
    "            if len(valid_distances) > 0:\n",
    "                labels[i] = int(valid_distances.min())\n",
    "            # if not found: stays at k_hops + 1 (no illicit in k-hop neighborhood)\n",
    "\n",
    "    return torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af557522",
   "metadata": {},
   "source": [
    "The final helper - I do realise that this is an obnoxiously long function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cumulative_graph_at_timestep_distance_within_k_hops_regression(current_time_step, nodes_df, edges_df, node_labels_df,\n",
    "                                             k_hops=2, horizon=3):\n",
    "    \"\"\"\n",
    "    Build cumulative graph with k-hop + multi-horizon labeling.\n",
    "    \n",
    "    Args:\n",
    "        current_time_step: int, current time step t\n",
    "        nodes_df: DataFrame with all node data\n",
    "        edges_df: DataFrame with all edge data\n",
    "        node_labels_df: DataFrame with node class labels\n",
    "        k_hops: int, neighborhood radius (default=2)\n",
    "        horizon: int, future time steps to check (default=3)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Data object, address_to_local_id dict)\n",
    "    \"\"\"\n",
    "    # get all nodes that appeared up to time t\n",
    "    nodes_up_to_t = nodes_df[nodes_df['Time step'] <= current_time_step].copy()\n",
    "    active_addresses = nodes_up_to_t['address'].unique()\n",
    "    address_to_local_id = {addr: idx for idx, addr in enumerate(active_addresses)}\n",
    "    \n",
    "    # get all edges up to time t\n",
    "    edges_up_to_t = edges_df[edges_df['Time step'] <= current_time_step]\n",
    "    \n",
    "    # build graph components\n",
    "    node_features = extract_node_features(nodes_up_to_t, active_addresses, address_to_local_id)\n",
    "    edge_index = build_edge_index(edges_up_to_t, address_to_local_id)\n",
    "    num_nodes = len(active_addresses)\n",
    "    \n",
    "    # distance within k-hops + multi-horizon based labels\n",
    "    labels = create_labels_k_hop_distance_multi_horizon(\n",
    "        current_time_step=current_time_step,\n",
    "        edges_df=edges_df,\n",
    "        node_labels_df=node_labels_df,\n",
    "        active_addresses=active_addresses,\n",
    "        address_to_local_id=address_to_local_id, # NOTE: those only contain until time t, so all good\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        k_hops=k_hops,\n",
    "        horizon=horizon\n",
    "    )\n",
    "    \n",
    "    node_classes = extract_node_classes(active_addresses, address_to_local_id, node_labels_df)\n",
    "    \n",
    "    # create PyG Data object\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        y=labels,\n",
    "        node_class=node_classes,\n",
    "        num_nodes=num_nodes\n",
    "    )\n",
    "    \n",
    "    return data, address_to_local_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8df260",
   "metadata": {},
   "source": [
    "Let's build the regression graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all graphs with distance with k-hops + multi-horizon labeling\n",
    "# Hyperparameters\n",
    "K_HOPS = 2\n",
    "HORIZON = 3\n",
    "\n",
    "cumulative_graphs_khop_distance = []\n",
    "address_mappings_khop_distance = []\n",
    "\n",
    "print(f\"Building graphs with k_hops={K_HOPS}, horizon={HORIZON}\\n\")\n",
    "\n",
    "for t in time_steps[:-HORIZON]:  # need horizon future time steps\n",
    "    print(f\"Building graph for time step {t}...\", end=\" \")\n",
    "    \n",
    "    graph_data, addr_mapping = build_cumulative_graph_at_timestep_distance_within_k_hops_regression(\n",
    "        current_time_step=t,\n",
    "        nodes_df=nodes_with_labels,\n",
    "        edges_df=edges_with_edge_labels,\n",
    "        node_labels_df=node_labels,\n",
    "        k_hops=K_HOPS,\n",
    "        horizon=HORIZON\n",
    "    )\n",
    "    \n",
    "    cumulative_graphs_khop_distance.append(graph_data)\n",
    "    address_mappings_khop_distance.append(addr_mapping)\n",
    "    \n",
    "    # Count nodes at each distance\n",
    "    label_counts = {}\n",
    "    for dist in range(K_HOPS + 2):  # 0, 1, 2, ..., k_hops, k_hops+1\n",
    "        count = (graph_data.y == dist).sum().item()\n",
    "        label_counts[dist] = count\n",
    "    \n",
    "    # Build the output string\n",
    "    counts_str = \", \".join([f\"d={i}: {label_counts[i]}\" for i in range(K_HOPS + 1)])\n",
    "    counts_str += f\", unreachable: {label_counts[K_HOPS + 1]}\"\n",
    "    \n",
    "    print(f\"Nodes: {graph_data.num_nodes}, Edges: {graph_data.edge_index.shape[1]}, \"\n",
    "          f\"{counts_str}\")\n",
    "\n",
    "print(f\"\\nTotal graphs created: {len(cumulative_graphs_khop_distance)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
