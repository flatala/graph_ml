{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static GCN Baseline\n",
    "\n",
    "**Objective**: 2-layer GCN using graph structure and node features.\n",
    "\n",
    "**Key principle**: Each node v evaluated at exactly t_first(v) + K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\n\nROOT = Path.cwd().parent.parent\nsys.path.insert(0, str(ROOT))\n\nfrom code_lib.temporal_node_classification_builder import (\n    TemporalNodeClassificationBuilder,\n    load_elliptic_data,\n    prepare_observation_window_graphs\n)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\nfrom tqdm.notebook import tqdm\nimport os\nimport random"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from test_config import EXPERIMENT_CONFIG\n",
    "\n",
    "CONFIG = EXPERIMENT_CONFIG.copy()\n",
    "# GCN-specific hyperparameters (FIXED for class imbalance)\n",
    "CONFIG['dropout'] = 0.3  # Reduced from 0.5 to prevent over-regularization\n",
    "CONFIG['learning_rate'] = 0.001  # Reduced from 0.01 for more stable training\n",
    "CONFIG['weight_decay'] = 1e-5  # Reduced from 5e-4 to allow model to fit minority class\n",
    "CONFIG['epochs'] = 200\n",
    "CONFIG['patience'] = 20\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Multi-Seed Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "SEEDS = [42, 123, 456]\nRESULTS_DIR = Path('../../results/static_gcn_multi_seed')\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Running experiments with {len(SEEDS)} seeds: {SEEDS}\")\nprint(f\"Results will be saved to: {RESULTS_DIR}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def remove_correlated_features(nodes_df, threshold=0.95, verbose=True):\n    \"\"\"\n    Remove highly correlated features from nodes DataFrame.\n    \"\"\"\n    exclude_cols = {'address', 'Time step', 'class'}\n    feature_cols = [col for col in nodes_df.columns\n                    if col not in exclude_cols and\n                    pd.api.types.is_numeric_dtype(nodes_df[col])]\n\n    sample_size = min(10000, len(nodes_df))\n    sample_df = nodes_df[feature_cols].sample(n=sample_size, random_state=42)\n    corr_matrix = sample_df.corr().abs()\n\n    to_remove = set()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i+1, len(corr_matrix.columns)):\n            if corr_matrix.iloc[i, j] > threshold:\n                to_remove.add(corr_matrix.columns[j])\n\n    features_to_keep = [col for col in feature_cols if col not in to_remove]\n\n    if verbose:\n        print(f\"Original features: {len(feature_cols)}\")\n        print(f\"Removed features:  {len(to_remove)}\")\n        print(f\"Kept features:     {len(features_to_keep)}\")\n\n    return features_to_keep"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load Data & Create Splits"
  },
  {
   "cell_type": "code",
   "source": "nodes_df, edges_df = load_elliptic_data(CONFIG['data_dir'], use_temporal_features=True)\n\nkept_features = remove_correlated_features(nodes_df, threshold=0.95, verbose=False)\n\nbuilder = TemporalNodeClassificationBuilder(\n    nodes_df=nodes_df,\n    edges_df=edges_df,\n    feature_cols=kept_features,\n    include_class_as_feature=False,\n    add_temporal_features=True,\n    cache_dir='../../graph_cache_reduced_features_fixed',\n    use_cache=True,\n    verbose=True\n)\n\nsplit = builder.get_train_val_test_split(\n    train_timesteps=CONFIG['train_timesteps'],\n    val_timesteps=CONFIG['val_timesteps'],\n    test_timesteps=CONFIG['test_timesteps'],\n    filter_unknown=True\n)\n\nprint(f\"Train: {len(split['train'])} nodes\")\nprint(f\"Val:   {len(split['val'])} nodes\")\nprint(f\"Test:  {len(split['test'])} nodes\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Per-Node Graphs\n",
    "\n",
    "Each node evaluated at t_first(v) + K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARING OBSERVATION WINDOW GRAPHS (PER-NODE EVALUATION)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "K = 0 (Each node evaluated at t_first + 0)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=5 to t=24\n",
      "  Unique graphs needed: 20\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t5_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t6_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t7_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t8_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t9_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t10_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t11_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t12_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t13_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t14_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t15_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t16_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t17_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t18_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t19_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t20_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t21_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t22_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t23_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t24_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=29 to t=31\n",
      "  Unique graphs needed: 3\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t29_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t30_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t31_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=37 to t=43\n",
      "  Unique graphs needed: 7\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t37_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t38_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t39_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t40_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t41_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t42_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t43_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "K = 3 (Each node evaluated at t_first + 3)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=8 to t=27\n",
      "  Unique graphs needed: 20\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t8_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t9_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t10_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t11_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t12_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t13_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t14_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t15_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t16_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t17_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t18_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t19_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t20_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t21_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t22_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t23_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t24_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t25_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t26_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t27_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=32 to t=34\n",
      "  Unique graphs needed: 3\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t32_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t33_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t34_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=40 to t=46\n",
      "  Unique graphs needed: 7\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t40_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t41_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t42_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t43_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t44_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t45_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t46_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "K = 5 (Each node evaluated at t_first + 5)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=10 to t=29\n",
      "  Unique graphs needed: 20\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t10_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t11_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t12_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t13_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t14_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t15_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t16_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t17_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t18_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t19_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t20_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t21_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t22_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t23_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t24_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t25_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t26_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t27_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t28_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t29_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=34 to t=36\n",
      "  Unique graphs needed: 3\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t34_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t35_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t36_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=42 to t=48\n",
      "  Unique graphs needed: 7\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t42_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t43_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t44_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t45_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t46_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t47_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  \u2705 Loaded cached graph from ../../graph_cache/graph_t48_metaTrue_classFalse_tempTrue_weightsFalse.pt\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "\u2705 PER-NODE OBSERVATION WINDOW GRAPHS PREPARED\n",
      "======================================================================\n",
      "\n",
      "Created graphs for 3 observation windows \u00d7 3 splits\n",
      "\n",
      "Usage (collect data from all graphs in split):\n",
      "  X_train = [g.x[g.eval_mask] for g in graphs[K]['train']['graphs'].values()]\n",
      "  X_train = torch.cat(X_train)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(CONFIG['device'])\n",
    "\n",
    "graphs = prepare_observation_window_graphs(\n",
    "    builder,\n",
    "    split['train'],\n",
    "    split['val'],\n",
    "    split['test'],\n",
    "    K_values=CONFIG['observation_windows'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticGCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "source": "def collect_detailed_predictions(model, graphs_dict, device):\n    \"\"\"\n    Collect detailed predictions for post-hoc analysis.\n    \"\"\"\n    model.eval()\n\n    all_node_indices = []\n    all_predictions = []\n    all_probs_class_0 = []\n    all_probs_class_1 = []\n    all_true_labels = []\n    all_eval_times = []\n\n    with torch.no_grad():\n        for eval_t, graph in graphs_dict.items():\n            logits = model(graph.x, graph.edge_index)\n            probs = F.softmax(logits, dim=1)\n\n            # Extract predictions for masked nodes\n            pred = logits[graph.eval_mask].argmax(dim=1).cpu().numpy()\n            prob_0 = probs[graph.eval_mask, 0].cpu().numpy()\n            prob_1 = probs[graph.eval_mask, 1].cpu().numpy()\n            true = graph.y[graph.eval_mask].cpu().numpy()\n\n            # Get node indices\n            node_idx = torch.where(graph.eval_mask)[0].cpu().numpy()\n            eval_times = np.full(len(node_idx), eval_t)\n\n            all_node_indices.append(node_idx)\n            all_predictions.append(pred)\n            all_probs_class_0.append(prob_0)\n            all_probs_class_1.append(prob_1)\n            all_true_labels.append(true)\n            all_eval_times.append(eval_times)\n\n    return {\n        'node_indices': np.concatenate(all_node_indices),\n        'predictions': np.concatenate(all_predictions),\n        'probs_class_0': np.concatenate(all_probs_class_0),\n        'probs_class_1': np.concatenate(all_probs_class_1),\n        'true_labels': np.concatenate(all_true_labels),\n        'eval_times': np.concatenate(all_eval_times)\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, graphs_dict, optimizer, criterion):\n    \"\"\"Train on all graphs in split - BATCHED VERSION for stability.\"\"\"\n    model.train()\n    \n    # Collect all masked nodes from all graphs into one batch\n    all_logits = []\n    all_labels = []\n    \n    for eval_t, graph in graphs_dict.items():\n        logits = model(graph.x, graph.edge_index)\n        # Only keep logits and labels for eval_mask nodes\n        all_logits.append(logits[graph.eval_mask])\n        all_labels.append(graph.y[graph.eval_mask])\n    \n    # Concatenate into single batch\n    all_logits = torch.cat(all_logits, dim=0)\n    all_labels = torch.cat(all_labels, dim=0)\n    \n    # Single backward pass for all graphs\n    optimizer.zero_grad()\n    loss = criterion(all_logits, all_labels)\n    loss.backward()\n    optimizer.step()\n    \n    # Compute accuracy\n    pred = all_logits.argmax(dim=1)\n    correct = (pred == all_labels).sum().item()\n    total = len(all_labels)\n    \n    return loss.item(), correct / total\n\n\ndef evaluate(model, graphs_dict):\n    \"\"\"Evaluate on all graphs in split.\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for eval_t, graph in graphs_dict.items():\n            logits = model(graph.x, graph.edge_index)\n            pred = logits[graph.eval_mask].argmax(dim=1).cpu().numpy()\n            true = graph.y[graph.eval_mask].cpu().numpy()\n            probs = F.softmax(logits[graph.eval_mask], dim=1)[:, 1].cpu().numpy()\n            \n            all_preds.append(pred)\n            all_labels.append(true)\n            all_probs.append(probs)\n    \n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n    all_probs = np.concatenate(all_probs)\n    \n    acc = accuracy_score(all_labels, all_preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, all_preds, average='binary', pos_label=1, zero_division=0\n    )\n    auc = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.5\n    \n    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1, 'auc': auc}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Train Models (Multi-Seed)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import copy\nfrom datetime import datetime\n\n# Storage for all seeds\nall_seeds_results = {}\nall_seeds_predictions = {}\n\ntotal_iterations = len(SEEDS) * len(CONFIG['observation_windows'])\ncurrent_iteration = 0\n\nprint(f\"Starting multi-seed training:\")\nprint(f\"  Seeds: {SEEDS}\")\nprint(f\"  Observation windows (K): {CONFIG['observation_windows']}\")\nprint(f\"  Total training runs: {total_iterations}\")\nprint(f\"=\" * 80)\n\nstart_time = datetime.now()\n\nfor seed_idx, seed in enumerate(SEEDS):\n    print(f\"\\n{'#' * 80}\")\n    print(f\"# SEED {seed_idx + 1}/{len(SEEDS)}: {seed}\")\n    print(f\"{'#' * 80}\\n\")\n\n    # Set all random seeds\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n    seed_results = {}\n    seed_predictions = {}\n    seed_models = {}\n\n    for K in CONFIG['observation_windows']:\n        current_iteration += 1\n\n        print(f\"\\n{'='*70}\")\n        print(f\"Seed {seed} | K={K} | Progress: {current_iteration}/{total_iterations}\")\n        print(f\"{'='*70}\")\n\n        train_graphs = graphs[K]['train']['graphs']\n        val_graphs = graphs[K]['val']['graphs']\n        test_graphs = graphs[K]['test']['graphs']\n\n        # Initialize model\n        num_features = list(train_graphs.values())[0].x.shape[1]\n        model = StaticGCN(\n            num_features=num_features,\n            hidden_dim=CONFIG['hidden_dim'],\n            num_classes=2,\n            dropout=CONFIG['dropout']\n        ).to(device)\n\n        optimizer = torch.optim.Adam(\n            model.parameters(),\n            lr=CONFIG['learning_rate'],\n            weight_decay=CONFIG['weight_decay']\n        )\n\n        # Class weights from train\n        all_train_labels = []\n        for g in train_graphs.values():\n            all_train_labels.append(g.y[g.eval_mask].cpu())\n        all_train_labels = torch.cat(all_train_labels).long()\n\n        class_counts = torch.bincount(all_train_labels)\n        class_weights = torch.sqrt(1.0 / class_counts.float())\n        class_weights = class_weights / class_weights.sum() * 2.0\n        class_weights = class_weights.to(device)\n\n        print(f\"Class distribution: {class_counts.tolist()}\")\n        print(f\"Class weights: {class_weights.tolist()}\")\n\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n\n        # Training loop\n        best_val_f1 = 0\n        patience_counter = 0\n        best_model_state = None\n\n        pbar = tqdm(range(CONFIG['epochs']), desc=f\"Seed={seed}, K={K}\")\n        for epoch in pbar:\n            train_loss, train_acc = train_epoch(model, train_graphs, optimizer, criterion)\n\n            if (epoch + 1) % 5 == 0:\n                val_metrics = evaluate(model, val_graphs)\n                train_metrics = evaluate(model, train_graphs)\n                pbar.set_postfix({\n                    'loss': f\"{train_loss:.4f}\",\n                    'train_f1': f\"{train_metrics['f1']:.4f}\",\n                    'val_f1': f\"{val_metrics['f1']:.4f}\"\n                })\n\n                if val_metrics['f1'] > best_val_f1:\n                    best_val_f1 = val_metrics['f1']\n                    patience_counter = 0\n                    best_model_state = copy.deepcopy(model.state_dict())\n                else:\n                    patience_counter += 1\n\n                if patience_counter >= CONFIG['patience']:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n\n        # Load best model\n        if best_model_state is not None:\n            model.load_state_dict(best_model_state)\n\n        # Evaluate\n        train_metrics = evaluate(model, train_graphs)\n        val_metrics = evaluate(model, val_graphs)\n        test_metrics = evaluate(model, test_graphs)\n\n        print(f\"\\nTrain: F1={train_metrics['f1']:.4f}, AUC={train_metrics['auc']:.4f}\")\n        print(f\"Val:   F1={val_metrics['f1']:.4f}, AUC={val_metrics['auc']:.4f}\")\n        print(f\"Test:  F1={test_metrics['f1']:.4f}, AUC={test_metrics['auc']:.4f}\")\n\n        # Collect detailed predictions\n        print(\"Collecting detailed predictions...\")\n        train_preds = collect_detailed_predictions(model, train_graphs, device)\n        val_preds = collect_detailed_predictions(model, val_graphs, device)\n        test_preds = collect_detailed_predictions(model, test_graphs, device)\n\n        # Store results\n        seed_results[K] = {\n            'train': train_metrics,\n            'val': val_metrics,\n            'test': test_metrics\n        }\n\n        seed_predictions[K] = {\n            'train': train_preds,\n            'val': val_preds,\n            'test': test_preds\n        }\n\n        seed_models[K] = model\n\n        # Save predictions immediately\n        for split_name, preds in [('train', train_preds), ('val', val_preds), ('test', test_preds)]:\n            save_path = RESULTS_DIR / f\"seed{seed}_k{K}_{split_name}_predictions.npz\"\n            np.savez_compressed(\n                save_path,\n                node_indices=preds['node_indices'],\n                predictions=preds['predictions'],\n                probs_class_0=preds['probs_class_0'],\n                probs_class_1=preds['probs_class_1'],\n                true_labels=preds['true_labels'],\n                eval_times=preds['eval_times']\n            )\n        print(f\"Saved predictions to {RESULTS_DIR}/seed{seed}_k{K}_*_predictions.npz\")\n\n    # Store results for this seed\n    all_seeds_results[seed] = seed_results\n    all_seeds_predictions[seed] = seed_predictions\n\n    # Save metrics for this seed\n    seed_metrics_data = []\n    for K in CONFIG['observation_windows']:\n        for split_name in ['train', 'val', 'test']:\n            metrics = seed_results[K][split_name]\n            seed_metrics_data.append({\n                'seed': seed,\n                'K': K,\n                'split': split_name,\n                'accuracy': metrics['accuracy'],\n                'precision': metrics['precision'],\n                'recall': metrics['recall'],\n                'f1': metrics['f1'],\n                'auc': metrics['auc']\n            })\n\n    seed_metrics_df = pd.DataFrame(seed_metrics_data)\n    seed_metrics_df.to_csv(RESULTS_DIR / f'seed{seed}_metrics.csv', index=False)\n    print(f\"\\nSaved metrics for seed {seed} to {RESULTS_DIR}/seed{seed}_metrics.csv\")\n\nend_time = datetime.now()\nelapsed = end_time - start_time\n\nprint(f\"\\n{'=' * 80}\")\nprint(f\"Multi-seed training complete!\")\nprint(f\"Total time: {elapsed}\")\nprint(f\"Results saved to: {RESULTS_DIR}\")\nprint(f\"{'=' * 80}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Results Summary"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Aggregate results across all seeds\naggregated_results = []\n\nfor seed in SEEDS:\n    for K in CONFIG['observation_windows']:\n        for split_name in ['train', 'val', 'test']:\n            metrics = all_seeds_results[seed][K][split_name]\n            aggregated_results.append({\n                'seed': seed,\n                'K': K,\n                'split': split_name,\n                'accuracy': metrics['accuracy'],\n                'precision': metrics['precision'],\n                'recall': metrics['recall'],\n                'f1': metrics['f1'],\n                'auc': metrics['auc']\n            })\n\nall_results_df = pd.DataFrame(aggregated_results)\n\n# Compute statistics across seeds for test set\ntest_results = all_results_df[all_results_df['split'] == 'test']\n\nsummary_stats = []\nfor K in CONFIG['observation_windows']:\n    k_results = test_results[test_results['K'] == K]\n\n    summary_stats.append({\n        'K': K,\n        'F1_mean': k_results['f1'].mean(),\n        'F1_std': k_results['f1'].std(),\n        'AUC_mean': k_results['auc'].mean(),\n        'AUC_std': k_results['auc'].std(),\n        'Precision_mean': k_results['precision'].mean(),\n        'Precision_std': k_results['precision'].std(),\n        'Recall_mean': k_results['recall'].mean(),\n        'Recall_std': k_results['recall'].std(),\n        'Accuracy_mean': k_results['accuracy'].mean(),\n        'Accuracy_std': k_results['accuracy'].std()\n    })\n\nsummary_df = pd.DataFrame(summary_stats)\n\nprint(\"\\nTest Set Performance Across Seeds (Mean \u00b1 Std):\")\nprint(\"=\" * 80)\nfor _, row in summary_df.iterrows():\n    print(f\"K={row['K']}:\")\n    print(f\"  F1:        {row['F1_mean']:.4f} \u00b1 {row['F1_std']:.4f}\")\n    print(f\"  AUC:       {row['AUC_mean']:.4f} \u00b1 {row['AUC_std']:.4f}\")\n    print(f\"  Precision: {row['Precision_mean']:.4f} \u00b1 {row['Precision_std']:.4f}\")\n    print(f\"  Recall:    {row['Recall_mean']:.4f} \u00b1 {row['Recall_std']:.4f}\")\n    print(f\"  Accuracy:  {row['Accuracy_mean']:.4f} \u00b1 {row['Accuracy_std']:.4f}\")\n    print()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Performance Visualization"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# F1 Score with error bars\nax = axes[0]\nf1_means = summary_df['F1_mean'].values\nf1_stds = summary_df['F1_std'].values\nax.errorbar(CONFIG['observation_windows'], f1_means, yerr=f1_stds,\n            marker='o', linewidth=2, capsize=5, capthick=2, color='steelblue')\nax.set_xlabel('Observation Window K', fontsize=12)\nax.set_ylabel('F1 Score', fontsize=12)\nax.set_title('F1 Score vs Observation Window (Mean \u00b1 Std)', fontsize=13, fontweight='bold')\nax.grid(True, alpha=0.3)\n\n# AUC with error bars\nax = axes[1]\nauc_means = summary_df['AUC_mean'].values\nauc_stds = summary_df['AUC_std'].values\nax.errorbar(CONFIG['observation_windows'], auc_means, yerr=auc_stds,\n            marker='o', linewidth=2, capsize=5, capthick=2, color='green')\nax.set_xlabel('Observation Window K', fontsize=12)\nax.set_ylabel('AUC', fontsize=12)\nax.set_title('AUC vs Observation Window (Mean \u00b1 Std)', fontsize=13, fontweight='bold')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Save Results"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Save aggregated summary statistics\nsummary_df.to_csv(RESULTS_DIR / 'multi_seed_summary_statistics.csv', index=False)\nprint(f\"Saved summary statistics to {RESULTS_DIR / 'multi_seed_summary_statistics.csv'}\")\n\n# Save all results (detailed)\nall_results_df.to_csv(RESULTS_DIR / 'all_seeds_all_metrics.csv', index=False)\nprint(f\"Saved all metrics to {RESULTS_DIR / 'all_seeds_all_metrics.csv'}\")\n\nprint(f\"\\nAll results saved to: {RESULTS_DIR}\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}