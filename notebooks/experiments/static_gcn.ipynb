{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static GCN Baseline\n",
    "\n",
    "**Objective**: 2-layer GCN using graph structure and node features.\n",
    "\n",
    "**Key principle**: Each node v evaluated at exactly t_first(v) + K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from code_lib.temporal_node_classification_builder import (\n",
    "    TemporalNodeClassificationBuilder,\n",
    "    load_elliptic_data,\n",
    "    prepare_observation_window_graphs\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "from test_config import EXPERIMENT_CONFIG\n",
    "\n",
    "CONFIG = EXPERIMENT_CONFIG.copy()\n",
    "# GCN-specific hyperparameters\n",
    "CONFIG['dropout'] = 0.5\n",
    "CONFIG['learning_rate'] = 0.01\n",
    "CONFIG['weight_decay'] = 5e-4\n",
    "CONFIG['epochs'] = 200\n",
    "CONFIG['patience'] = 20\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Create Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 96470 nodes\n",
      "Val:   9884 nodes\n",
      "Test:  39305 nodes\n"
     ]
    }
   ],
   "source": [
    "nodes_df, edges_df = load_elliptic_data(CONFIG['data_dir'], use_temporal_features=True)\n",
    "\n",
    "builder = TemporalNodeClassificationBuilder(\n",
    "    nodes_df=nodes_df,\n",
    "    edges_df=edges_df,\n",
    "    include_class_as_feature=False,\n",
    "    add_temporal_features=True,\n",
    "    cache_dir='../../graph_cache',\n",
    "    use_cache=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "split = builder.get_train_val_test_split(\n",
    "    train_timesteps=CONFIG['train_timesteps'],\n",
    "    val_timesteps=CONFIG['val_timesteps'],\n",
    "    test_timesteps=CONFIG['test_timesteps'],\n",
    "    filter_unknown=True\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(split['train'])} nodes\")\n",
    "print(f\"Val:   {len(split['val'])} nodes\")\n",
    "print(f\"Test:  {len(split['test'])} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Per-Node Graphs\n",
    "\n",
    "Each node evaluated at t_first(v) + K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARING OBSERVATION WINDOW GRAPHS (PER-NODE EVALUATION)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "K = 0 (Each node evaluated at t_first + 0)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=5 to t=24\n",
      "  Unique graphs needed: 20\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=29 to t=31\n",
      "  Unique graphs needed: 3\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=37 to t=43\n",
      "  Unique graphs needed: 7\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "K = 3 (Each node evaluated at t_first + 3)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=8 to t=27\n",
      "  Unique graphs needed: 20\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=32 to t=34\n",
      "  Unique graphs needed: 3\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=40 to t=46\n",
      "  Unique graphs needed: 7\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "K = 5 (Each node evaluated at t_first + 5)\n",
      "======================================================================\n",
      "\n",
      "TRAIN split:\n",
      "  Nodes to evaluate: 96,470\n",
      "  Evaluation times: t=10 to t=29\n",
      "  Unique graphs needed: 20\n",
      "  Total eval nodes across all graphs: 96,470\n",
      "\n",
      "VAL split:\n",
      "  Nodes to evaluate: 9,884\n",
      "  Evaluation times: t=34 to t=36\n",
      "  Unique graphs needed: 3\n",
      "  Total eval nodes across all graphs: 9,884\n",
      "\n",
      "TEST split:\n",
      "  Nodes to evaluate: 39,305\n",
      "  Evaluation times: t=42 to t=48\n",
      "  Unique graphs needed: 7\n",
      "  Total eval nodes across all graphs: 39,305\n",
      "\n",
      "======================================================================\n",
      "✅ PER-NODE OBSERVATION WINDOW GRAPHS PREPARED\n",
      "======================================================================\n",
      "\n",
      "Created graphs for 3 observation windows × 3 splits\n",
      "\n",
      "Usage (collect data from all graphs in split):\n",
      "  X_train = [g.x[g.eval_mask] for g in graphs[K]['train']['graphs'].values()]\n",
      "  X_train = torch.cat(X_train)\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(CONFIG['device'])\n",
    "\n",
    "graphs = prepare_observation_window_graphs(\n",
    "    builder,\n",
    "    split['train'],\n",
    "    split['val'],\n",
    "    split['test'],\n",
    "    K_values=CONFIG['observation_windows'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticGCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, graphs_dict, optimizer, criterion):\n",
    "    \"\"\"Train on all graphs in split.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for eval_t, graph in graphs_dict.items():\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(graph.x, graph.edge_index)\n",
    "        \n",
    "        # Loss only on masked nodes\n",
    "        loss = criterion(logits[graph.eval_mask], graph.y[graph.eval_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * graph.eval_mask.sum().item()\n",
    "        pred = logits[graph.eval_mask].argmax(dim=1)\n",
    "        total_correct += (pred == graph.y[graph.eval_mask]).sum().item()\n",
    "        total_samples += graph.eval_mask.sum().item()\n",
    "    \n",
    "    return total_loss / total_samples, total_correct / total_samples\n",
    "\n",
    "\n",
    "def evaluate(model, graphs_dict):\n",
    "    \"\"\"Evaluate on all graphs in split.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eval_t, graph in graphs_dict.items():\n",
    "            logits = model(graph.x, graph.edge_index)\n",
    "            pred = logits[graph.eval_mask].argmax(dim=1).cpu().numpy()\n",
    "            true = graph.y[graph.eval_mask].cpu().numpy()\n",
    "            probs = F.softmax(logits[graph.eval_mask], dim=1)[:, 1].cpu().numpy()\n",
    "            \n",
    "            all_preds.append(pred)\n",
    "            all_labels.append(true)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average='binary', pos_label=1, zero_division=0\n",
    "    )\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(np.unique(all_labels)) > 1 else 0.5\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1, 'auc': auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models (Per-K Retraining)\n",
    "\n",
    "Separate model for each K value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training with K=0\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7a0b8da9d047f2bcd872032adf3499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "K=0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 24.09 GB, other allocations: 5.98 GB, max allowed: 30.19 GB). Tried to allocate 343.31 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m pbar = tqdm(\u001b[38;5;28mrange\u001b[39m(CONFIG[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]), desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mK=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     51\u001b[39m         val_metrics = evaluate(model, val_graphs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, graphs_dict, optimizer, criterion)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m eval_t, graph \u001b[38;5;129;01min\u001b[39;00m graphs_dict.items():\n\u001b[32m      9\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Loss only on masked nodes\u001b[39;00m\n\u001b[32m     13\u001b[39m     loss = criterion(logits[graph.eval_mask], graph.y[graph.eval_mask])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mStaticGCN.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     x = F.relu(x)\n\u001b[32m     11\u001b[39m     x = F.dropout(x, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    260\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin(x)\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     out = out + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/4v/v9ffdg4s0491dlql1520s_200000gn/T/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_kaq1eo53.py:183\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m    177\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.update(\n\u001b[32m    178\u001b[39m         out,\n\u001b[32m    179\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/var/folders/4v/v9ffdg4s0491dlql1520s_200000gn/T/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_kaq1eo53.py:96\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[32m     95\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_size(size, j, x)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     x_j = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     98\u001b[39m     x_j = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[39m, in \u001b[36mMessagePassing._index_select\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src.index_select(\u001b[38;5;28mself\u001b[39m.node_dim, index)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:290\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.max() >= src.size(\u001b[38;5;28mself\u001b[39m.node_dim)):\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    283\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound indices in \u001b[39m\u001b[33m'\u001b[39m\u001b[33medge_index\u001b[39m\u001b[33m'\u001b[39m\u001b[33m that are larger \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    284\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    287\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc.size(\u001b[38;5;28mself\u001b[39m.node_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour node feature matrix and try again.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/graph-ml/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[39m, in \u001b[36mMessagePassing._index_select_safe\u001b[39m\u001b[34m(self, src, index)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index.min() < \u001b[32m0\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 24.09 GB, other allocations: 5.98 GB, max allowed: 30.19 GB). Tried to allocate 343.31 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "models = {}\n",
    "\n",
    "for K in CONFIG['observation_windows']:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with K={K}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    train_graphs = graphs[K]['train']['graphs']\n",
    "    val_graphs = graphs[K]['val']['graphs']\n",
    "    test_graphs = graphs[K]['test']['graphs']\n",
    "    \n",
    "    # Initialize model\n",
    "    num_features = list(train_graphs.values())[0].x.shape[1]\n",
    "    model = StaticGCN(\n",
    "        num_features=num_features,\n",
    "        hidden_dim=CONFIG['hidden_dim'],\n",
    "        num_classes=2,\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Compute class weights from all training graphs\n",
    "    all_train_labels = []\n",
    "    for g in train_graphs.values():\n",
    "        all_train_labels.append(g.y[g.eval_mask].cpu())\n",
    "    all_train_labels = torch.cat(all_train_labels).long()\n",
    "    \n",
    "    class_counts = torch.bincount(all_train_labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    class_weights = class_weights.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    pbar = tqdm(range(CONFIG['epochs']), desc=f\"K={K}\")\n",
    "    for epoch in pbar:\n",
    "        train_loss, train_acc = train_epoch(model, train_graphs, optimizer, criterion)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            val_metrics = evaluate(model, val_graphs)\n",
    "            pbar.set_postfix({'loss': f\"{train_loss:.4f}\", 'val_f1': f\"{val_metrics['f1']:.4f}\"})\n",
    "            \n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= CONFIG['patience']:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    train_metrics = evaluate(model, train_graphs)\n",
    "    val_metrics = evaluate(model, val_graphs)\n",
    "    test_metrics = evaluate(model, test_graphs)\n",
    "    \n",
    "    print(f\"\\nTrain: F1={train_metrics['f1']:.4f}, AUC={train_metrics['auc']:.4f}\")\n",
    "    print(f\"Val:   F1={val_metrics['f1']:.4f}, AUC={val_metrics['auc']:.4f}\")\n",
    "    print(f\"Test:  F1={test_metrics['f1']:.4f}, AUC={test_metrics['auc']:.4f}\")\n",
    "    \n",
    "    results[K] = {'train': train_metrics, 'val': val_metrics, 'test': test_metrics}\n",
    "    models[K] = model\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ Training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data = []\n",
    "\n",
    "for K in CONFIG['observation_windows']:\n",
    "    metrics = results[K]['test']\n",
    "    comparison_data.append({\n",
    "        'K': K,\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'Precision': f\"{metrics['precision']:.4f}\",\n",
    "        'Recall': f\"{metrics['recall']:.4f}\",\n",
    "        'F1': f\"{metrics['f1']:.4f}\",\n",
    "        'AUC': f\"{metrics['auc']:.4f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F1 Score\n",
    "ax = axes[0]\n",
    "f1_scores = [results[K]['test']['f1'] for K in CONFIG['observation_windows']]\n",
    "ax.plot(CONFIG['observation_windows'], f1_scores, marker='o', linewidth=2, color='steelblue')\n",
    "ax.set_xlabel('Observation Window K', fontsize=12)\n",
    "ax.set_ylabel('F1 Score', fontsize=12)\n",
    "ax.set_title('F1 Score vs Observation Window', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "ax = axes[1]\n",
    "auc_scores = [results[K]['test']['auc'] for K in CONFIG['observation_windows']]\n",
    "ax.plot(CONFIG['observation_windows'], auc_scores, marker='o', linewidth=2, color='green')\n",
    "ax.set_xlabel('Observation Window K', fontsize=12)\n",
    "ax.set_ylabel('AUC', fontsize=12)\n",
    "ax.set_title('AUC vs Observation Window', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('../../results', exist_ok=True)\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "\n",
    "comparison_df.to_csv('../../results/static_gcn_results.csv', index=False)\n",
    "print(\"Results saved to ../../results/static_gcn_results.csv\")\n",
    "\n",
    "for K, model in models.items():\n",
    "    torch.save(model.state_dict(), f'../../models/static_gcn_k{K}.pt')\n",
    "print(f\"Models saved to ../../models/static_gcn_k*.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
