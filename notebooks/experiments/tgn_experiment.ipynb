{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temporal Graph Network Experiment\n",
        "\n",
        "This notebook trains a Temporal Graph Network (TGN) on the Elliptic event stream using the same data preparation and evaluation protocol as the other experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\luket\\Documents\\Fork\\graph_ml\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "while PROJECT_ROOT != PROJECT_ROOT.parent and not (PROJECT_ROOT / \"code_lib\").exists():\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "if not (PROJECT_ROOT / \"code_lib\").exists():\n",
        "    raise RuntimeError(\"Unable to locate 'code_lib' directory from current working directory\")\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu128\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import average_precision_score, f1_score\n",
        "\n",
        "from torch_geometric.loader import TemporalDataLoader\n",
        "from torch_geometric.nn.models.tgn import TGNMemory, MeanAggregator, LastNeighborLoader\n",
        "\n",
        "from code_lib.temporal_node_classification_builder import (\n",
        "    TemporalNodeClassificationBuilder,\n",
        "    load_elliptic_data,\n",
        ")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config summary:\n",
            "  batch_size: 4096\n",
            "  learning_rate: 0.002\n",
            "  weight_decay: 1e-05\n",
            "  dropout: 0.1\n",
            "  epochs: 30\n",
            "  patience: 5\n",
            "  tgn_memory_dim: 64\n",
            "  tgn_msg_hidden: 64\n",
            "  tgn_msg_out: 32\n",
            "Seeds: [42, 123]\n",
            "Device: cuda\n",
            "Results directory: c:\\Users\\luket\\Documents\\Fork\\graph_ml\\results\\tgn_event_stream\n"
          ]
        }
      ],
      "source": [
        "from test_config import EXPERIMENT_CONFIG\n",
        "\n",
        "CONFIG = EXPERIMENT_CONFIG.copy()\n",
        "CONFIG.update({\n",
        "    \"batch_size\": 4096,\n",
        "    \"learning_rate\": 2e-3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"dropout\": 0.1,\n",
        "    \"epochs\": 30,\n",
        "    \"patience\": 5,\n",
        "    \"tgn_memory_dim\": 64,\n",
        "    \"tgn_time_dim\": 8,\n",
        "    \"tgn_msg_hidden\": 64,\n",
        "    \"tgn_msg_out\": 32,\n",
        "    \"tgn_decoder_hidden\": 64,\n",
        "    \"tgn_neighbor_size\": 20,\n",
        "})\n",
        "\n",
        "device_str = CONFIG.get(\"device\", \"cpu\")\n",
        "if device_str.startswith(\"cuda\") and not torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "else:\n",
        "    DEVICE = torch.device(device_str)\n",
        "\n",
        "SEEDS = [42, 123]\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\" / \"tgn_event_stream\"\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Config summary:\")\n",
        "for key in [\n",
        "    \"batch_size\", \"learning_rate\", \"weight_decay\", \"dropout\",\n",
        "    \"epochs\", \"patience\", \"tgn_memory_dim\", \"tgn_msg_hidden\", \"tgn_msg_out\"\n",
        "]:\n",
        "    print(f\"  {key}: {CONFIG[key]}\")\n",
        "print(f\"Seeds: {SEEDS}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Results directory: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading trmporal features...\n",
            "Loading node classes...\n",
            "Loading edges...\n",
            "Created cache directory: c:\\Users\\luket\\Documents\\Fork\\graph_ml\\graph_cache_tgn\n",
            "  Pre-processing node features by (address, timestep)...\n",
            "  Pre-processing edges by timestep...\n",
            "  Average new nodes per timestep: 16794.7\n",
            "Initialized TemporalNodeClassificationBuilder\n",
            "  Total nodes: 822942\n",
            "  Total edges: 2868964\n",
            "  Time steps: 1 to 49\n",
            "  Feature columns (116): ['in_num', 'in_total_fees', 'in_mean_fees', 'in_median_fees', 'in_total_btc_in']...\n",
            "  Include class as feature: False\n",
            "  Add temporal features: True\n",
            "  Add edge weights: False\n",
            "\n",
            "Temporal Split Summary:\n",
            "  Train: timesteps 5-26, 104704 nodes\n",
            "    Illicit: 6698, Licit: 98006\n",
            "Training illicit ratio: 0.06397081295843521\n",
            "  Val:   timesteps 27-31, 11230 nodes\n",
            "    Illicit: 809, Licit: 10421\n",
            "Validation illicit ratio: 0.07203918076580587\n",
            "  Test:  timesteps 32-40, 45963 nodes\n",
            "    Illicit: 3682, Licit: 42281\n",
            "Test illicit ratio: 0.08010791288645215\n",
            "Train nodes: 104704\n",
            "Val nodes:   11230\n",
            "Test nodes:  45963\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = PROJECT_ROOT / \"elliptic_dataset\"\n",
        "nodes_df, edges_df = load_elliptic_data(str(DATA_DIR), use_temporal_features=True)\n",
        "\n",
        "builder = TemporalNodeClassificationBuilder(\n",
        "    nodes_df=nodes_df,\n",
        "    edges_df=edges_df,\n",
        "    include_class_as_feature=False,\n",
        "    add_temporal_features=True,\n",
        "    add_edge_weights=False,\n",
        "    cache_dir=str(PROJECT_ROOT / \"graph_cache_tgn\"),\n",
        "    use_cache=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "split = builder.get_train_val_test_split(\n",
        "    train_timesteps=CONFIG['train_timesteps'],\n",
        "    val_timesteps=CONFIG['val_timesteps'],\n",
        "    test_timesteps=CONFIG['test_timesteps'],\n",
        "    filter_unknown=True,\n",
        ")\n",
        "\n",
        "print(f\"Train nodes: {len(split['train'])}\")\n",
        "print(f\"Val nodes:   {len(split['val'])}\")\n",
        "print(f\"Test nodes:  {len(split['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building snapshot graphs: 100%|██████████| 36/36 [00:05<00:00,  6.68it/s]\n",
            "Building snapshot graphs: 100%|██████████| 36/36 [00:06<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Events per split:\n",
            "  train: 1547601 events (t in [5, 26])\n",
            "  val: 121047 events (t in [27, 31])\n",
            "  test: 765003 events (t in [32, 40])\n",
            "Raw message dimension: 234\n",
            "Total nodes: 822942\n"
          ]
        }
      ],
      "source": [
        "event_stream = builder.build_event_stream(\n",
        "    start_timestep=CONFIG['train_timesteps'][0],\n",
        "    end_timestep=CONFIG['test_timesteps'][1],\n",
        "    dense=False,\n",
        "    include_edge_attr=False,\n",
        ")\n",
        "\n",
        "def binarize_labels(data):\n",
        "    if hasattr(data, \"y\"):\n",
        "        data.y = (data.y == 1).long()\n",
        "\n",
        "binarize_labels(event_stream)\n",
        "\n",
        "splits = builder.get_event_stream_split(\n",
        "    train_timesteps=CONFIG['train_timesteps'],\n",
        "    val_timesteps=CONFIG['val_timesteps'],\n",
        "    test_timesteps=CONFIG['test_timesteps'],\n",
        "    dense=False,\n",
        "    include_edge_attr=False,\n",
        ")\n",
        "\n",
        "for data in splits.values():\n",
        "    binarize_labels(data)\n",
        "\n",
        "print(\"Events per split:\")\n",
        "for name, data in splits.items():\n",
        "    if data.t.numel():\n",
        "        t_min = int(data.t.min())\n",
        "        t_max = int(data.t.max())\n",
        "    else:\n",
        "        t_min = t_max = None\n",
        "    print(f\"  {name}: {data.src.numel()} events (t in [{t_min}, {t_max}])\")\n",
        "\n",
        "raw_msg_dim = event_stream.msg.size(-1)\n",
        "num_nodes = builder.nodes_df['address'].nunique()\n",
        "\n",
        "print(f\"Raw message dimension: {raw_msg_dim}\")\n",
        "print(f\"Total nodes: {num_nodes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_loader(data, batch_size, shuffle):\n",
        "    return TemporalDataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    memory_dim: int\n",
        "    time_dim: int\n",
        "    msg_hidden: int\n",
        "    msg_out: int\n",
        "    decoder_hidden: int\n",
        "    neighbor_size: int\n",
        "    dropout: float\n",
        "    lr: float\n",
        "    weight_decay: float\n",
        "    batch_size: int\n",
        "    epochs: int\n",
        "    patience: int\n",
        "\n",
        "model_cfg = ModelConfig(\n",
        "    memory_dim=CONFIG['tgn_memory_dim'],\n",
        "    time_dim=CONFIG['tgn_time_dim'],\n",
        "    msg_hidden=CONFIG['tgn_msg_hidden'],\n",
        "    msg_out=CONFIG['tgn_msg_out'],\n",
        "    decoder_hidden=CONFIG['tgn_decoder_hidden'],\n",
        "    neighbor_size=CONFIG['tgn_neighbor_size'],\n",
        "    dropout=CONFIG['dropout'],\n",
        "    lr=CONFIG['learning_rate'],\n",
        "    weight_decay=CONFIG['weight_decay'],\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    epochs=CONFIG['epochs'],\n",
        "    patience=CONFIG['patience'],\n",
        ")\n",
        "\n",
        "class MLPMessage(nn.Module):\n",
        "    def __init__(self, raw_msg_dim, hidden_dim, out_dim, dropout, memory_dim, time_dim):\n",
        "        super().__init__()\n",
        "        in_dim = 2 * memory_dim + raw_msg_dim + time_dim\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "        self.out_channels = out_dim\n",
        "\n",
        "    def forward(self, z_src, z_dst, raw_msg, t_enc):\n",
        "        h = torch.cat([z_src, z_dst, raw_msg, t_enc], dim=-1)\n",
        "        return self.net(h)\n",
        "\n",
        "class LinkPredictor(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.lin2 = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, z_src, z_dst):\n",
        "        h = torch.cat([z_src, z_dst], dim=-1)\n",
        "        h = self.dropout(F.relu(self.lin1(h)))\n",
        "        return self.lin2(h).view(-1)\n",
        "\n",
        "def build_modules(cfg: ModelConfig):\n",
        "    message_module = MLPMessage(\n",
        "        raw_msg_dim=raw_msg_dim,\n",
        "        hidden_dim=cfg.msg_hidden,\n",
        "        out_dim=cfg.msg_out,\n",
        "        dropout=cfg.dropout,\n",
        "        memory_dim=cfg.memory_dim,\n",
        "        time_dim=cfg.time_dim,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    memory = TGNMemory(\n",
        "        num_nodes=num_nodes,\n",
        "        raw_msg_dim=raw_msg_dim,\n",
        "        memory_dim=cfg.memory_dim,\n",
        "        time_dim=cfg.time_dim,\n",
        "        message_module=message_module,\n",
        "        aggregator_module=MeanAggregator(),\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    neighbor_loader = LastNeighborLoader(\n",
        "        num_nodes=num_nodes,\n",
        "        size=cfg.neighbor_size,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    decoder = LinkPredictor(\n",
        "        in_dim=cfg.memory_dim * 2,\n",
        "        hidden_dim=cfg.decoder_hidden,\n",
        "        dropout=cfg.dropout,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        list(memory.parameters()) + list(decoder.parameters()),\n",
        "        lr=cfg.lr,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "    )\n",
        "\n",
        "    return memory, neighbor_loader, decoder, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def _gather_embeddings(memory, batch, assoc_buffer):\n",
        "    n_id = torch.cat([batch.src, batch.dst]).unique()\n",
        "    z_mem, _ = memory(n_id)\n",
        "    assoc_buffer[n_id] = torch.arange(n_id.size(0), device=assoc_buffer.device)\n",
        "    src_idx = assoc_buffer[batch.src]\n",
        "    dst_idx = assoc_buffer[batch.dst]\n",
        "    assoc_buffer[n_id] = -1\n",
        "    return z_mem[src_idx], z_mem[dst_idx]\n",
        "\n",
        "def run_epoch(loader, memory, neighbor_loader, decoder, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    memory.train(is_train)\n",
        "    decoder.train(is_train)\n",
        "    memory.reset_state()\n",
        "    neighbor_loader.reset_state()\n",
        "    assoc_buffer = torch.full((num_nodes,), -1, device=DEVICE, dtype=torch.long)\n",
        "    total_loss = 0.0\n",
        "    total_events = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(DEVICE)\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        z_src, z_dst = _gather_embeddings(memory, batch, assoc_buffer)\n",
        "        logits = decoder(z_src, z_dst)\n",
        "        loss = criterion(logits, batch.y.float())\n",
        "\n",
        "        if is_train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(memory.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            memory.detach()\n",
        "\n",
        "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
        "        neighbor_loader.insert(batch.src, batch.dst)\n",
        "        if not is_train:\n",
        "            memory.detach()\n",
        "\n",
        "        num_events = batch.src.size(0)\n",
        "        total_loss += float(loss.item()) * num_events\n",
        "        total_events += num_events\n",
        "\n",
        "    return total_loss / max(total_events, 1), total_events\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader, memory, neighbor_loader, decoder):\n",
        "    memory.eval()\n",
        "    decoder.eval()\n",
        "    memory.reset_state()\n",
        "    neighbor_loader.reset_state()\n",
        "    assoc_buffer = torch.full((num_nodes,), -1, device=DEVICE, dtype=torch.long)\n",
        "\n",
        "    preds = []\n",
        "    targets = []\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(DEVICE)\n",
        "        z_src, z_dst = _gather_embeddings(memory, batch, assoc_buffer)\n",
        "        logits = decoder(z_src, z_dst)\n",
        "        probs = torch.sigmoid(logits).detach().cpu()\n",
        "        preds.append(probs)\n",
        "        targets.append(batch.y.float().detach().cpu())\n",
        "\n",
        "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
        "        neighbor_loader.insert(batch.src, batch.dst)\n",
        "        memory.detach()\n",
        "\n",
        "    if not preds:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    y_score = torch.cat(preds).numpy()\n",
        "    y_true = torch.cat(targets).numpy()\n",
        "\n",
        "    ap = average_precision_score(y_true, y_score)\n",
        "    f1 = f1_score(y_true, (y_score > 0.5).astype(int))\n",
        "    return ap, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 77) (3469781265.py, line 77)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 77)\n"
          ]
        }
      ],
      "source": [
        "run_summaries = []\n",
        "history_records = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"===== Training seed {seed} =====\")\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    memory, neighbor_loader, decoder, optimizer = build_modules(model_cfg)\n",
        "\n",
        "    train_loader = make_loader(splits['train'], model_cfg.batch_size, shuffle=True)\n",
        "    val_loader = make_loader(splits['val'], model_cfg.batch_size, shuffle=False)\n",
        "    test_loader = make_loader(splits['test'], model_cfg.batch_size, shuffle=False)\n",
        "\n",
        "    best_state = None\n",
        "    best_val_ap = -float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(model_cfg.epochs):\n",
        "        train_loss, _ = run_epoch(train_loader, memory, neighbor_loader, decoder, optimizer)\n",
        "        val_ap, val_f1 = evaluate(val_loader, memory, neighbor_loader, decoder)\n",
        "\n",
        "        history_records.append({\n",
        "            'seed': seed,\n",
        "            'epoch': epoch + 1,\n",
        "            'train_loss': train_loss,\n",
        "            'val_ap': val_ap,\n",
        "            'val_f1': val_f1,\n",
        "        })\n",
        "\n",
        "        print(f\"Epoch {epoch+1:03d} | train_loss={train_loss:.4f} | val_AP={val_ap:.4f} | val_F1={val_f1:.4f}\")\n",
        "\n",
        "        if val_ap > best_val_ap:\n",
        "            best_val_ap = val_ap\n",
        "            patience_counter = 0\n",
        "            best_state = {\n",
        "                'memory': copy.deepcopy(memory.state_dict()),\n",
        "                'decoder': copy.deepcopy(decoder.state_dict()),\n",
        "            }\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= model_cfg.patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        memory.load_state_dict(best_state['memory'])\n",
        "        decoder.load_state_dict(best_state['decoder'])\n",
        "\n",
        "    train_ap, train_f1 = evaluate(train_loader, memory, neighbor_loader, decoder)\n",
        "    val_ap, val_f1 = evaluate(val_loader, memory, neighbor_loader, decoder)\n",
        "    test_ap, test_f1 = evaluate(test_loader, memory, neighbor_loader, decoder)\n",
        "\n",
        "    run_summaries.append({\n",
        "        'seed': seed,\n",
        "        'train_ap': train_ap,\n",
        "        'train_f1': train_f1,\n",
        "        'val_ap': val_ap,\n",
        "        'val_f1': val_f1,\n",
        "        'test_ap': test_ap,\n",
        "        'test_f1': test_f1,\n",
        "        'best_val_ap': best_val_ap,\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(run_summaries)\n",
        "history_df = pd.DataFrame(history_records)\n",
        "\n",
        "results_path = RESULTS_DIR / 'tgn_metrics.csv'\n",
        "history_path = RESULTS_DIR / 'tgn_training_history.csv'\n",
        "results_df.to_csv(results_path, index=False)\n",
        "history_df.to_csv(history_path, index=False)\n",
        "\n",
        "print(f\"Saved run summaries to {results_path}\")\n",
        "print(f\"Saved training history to {history_path}\")\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.describe(include=\"all\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.11.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
