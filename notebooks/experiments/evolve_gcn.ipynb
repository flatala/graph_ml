{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvolveGCN - Temporal GNN\n",
    "\n",
    "Trains a temporal GNN that processes graph sequences over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from code_lib.temporal_node_classification_builder import (\n",
    "    TemporalNodeClassificationBuilder,\n",
    "    load_elliptic_data,\n",
    "    prepare_temporal_model_graphs\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_dir': '../../elliptic_dataset',\n",
    "    'train_timesteps': (5, 29),\n",
    "    'val_timesteps': (30, 33),\n",
    "    'test_timesteps': (34, 42),\n",
    "    'observation_windows': [0, 5],  # Start with 0 and 5 for comparison\n",
    "    'hidden_dim': 64,\n",
    "    'dropout': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'weight_decay': 5e-4,\n",
    "    'epochs': 50,\n",
    "    'patience': 10,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df, edges_df = load_elliptic_data(CONFIG['data_dir'], use_temporal_features=True)\n",
    "\n",
    "builder = TemporalNodeClassificationBuilder(\n",
    "    nodes_df=nodes_df,\n",
    "    edges_df=edges_df,\n",
    "    include_class_as_feature=False,\n",
    "    add_temporal_features=True,\n",
    "    cache_dir='../../graph_cache',\n",
    "    use_cache=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "split = builder.get_train_val_test_split(\n",
    "    train_timesteps=CONFIG['train_timesteps'],\n",
    "    val_timesteps=CONFIG['val_timesteps'],\n",
    "    test_timesteps=CONFIG['test_timesteps'],\n",
    "    filter_unknown=True\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(split['train'])} nodes\")\n",
    "print(f\"Val:   {len(split['val'])} nodes\")\n",
    "print(f\"Test:  {len(split['test'])} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Temporal Graph Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(CONFIG['device'])\n",
    "\n",
    "sequences = prepare_temporal_model_graphs(\n",
    "    builder,\n",
    "    split['train'],\n",
    "    split['val'],\n",
    "    split['test'],\n",
    "    K_values=CONFIG['observation_windows'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Temporal GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGCN(nn.Module):\n",
    "    \"\"\"Simple temporal GCN that processes sequences with LSTM.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, hidden_dim, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(num_features, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, graphs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            graphs: List of Data objects representing temporal sequence\n",
    "        Returns:\n",
    "            logits: [num_nodes, num_classes] for the last graph\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        # Process each timestep with GCN\n",
    "        for graph in graphs:\n",
    "            x = self.gcn1(graph.x, graph.edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x = self.gcn2(x, graph.edge_index)\n",
    "            embeddings.append(x)\n",
    "        \n",
    "        # Stack embeddings: [num_nodes, seq_len, hidden_dim]\n",
    "        # Note: assumes same nodes across all timesteps (which is true for our setup)\n",
    "        embeddings = torch.stack(embeddings, dim=1)\n",
    "        \n",
    "        # Process temporal sequence with LSTM\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        \n",
    "        # Use last timestep output\n",
    "        final_emb = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(final_emb)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, graphs, optimizer, criterion):\n",
    "    \"\"\"Train on temporal sequence.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass through sequence\n",
    "    logits = model(graphs)\n",
    "    \n",
    "    # Compute loss on last graph's eval mask\n",
    "    last_graph = graphs[-1]\n",
    "    mask = last_graph.eval_mask\n",
    "    loss = criterion(logits[mask], last_graph.y[mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = logits[mask].argmax(dim=1)\n",
    "        acc = (pred == last_graph.y[mask]).float().mean().item()\n",
    "    \n",
    "    return loss.item(), acc\n",
    "\n",
    "\n",
    "def evaluate(model, graphs):\n",
    "    \"\"\"Evaluate on temporal sequence.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(graphs)\n",
    "        \n",
    "        # Evaluate on last graph's eval mask\n",
    "        last_graph = graphs[-1]\n",
    "        mask = last_graph.eval_mask\n",
    "        \n",
    "        pred = logits[mask].argmax(dim=1).cpu().numpy()\n",
    "        true = last_graph.y[mask].cpu().numpy()\n",
    "        probs = F.softmax(logits[mask], dim=1)[:, 1].cpu().numpy()\n",
    "        \n",
    "        acc = accuracy_score(true, pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            true, pred, average='binary', pos_label=1, zero_division=0\n",
    "        )\n",
    "        auc = roc_auc_score(true, probs) if len(np.unique(true)) > 1 else 0.5\n",
    "    \n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1, 'auc': auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "models = {}\n",
    "\n",
    "for K in CONFIG['observation_windows']:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with K={K}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    train_seq = sequences[K]['train']\n",
    "    val_seq = sequences[K]['val']\n",
    "    test_seq = sequences[K]['test']\n",
    "    \n",
    "    print(f\"Train sequence: {train_seq['sequence_length']} timesteps\")\n",
    "    print(f\"Val sequence:   {val_seq['sequence_length']} timesteps\")\n",
    "    print(f\"Test sequence:  {test_seq['sequence_length']} timesteps\")\n",
    "    \n",
    "    # Initialize model\n",
    "    num_features = train_seq['graphs'][0].x.shape[1]\n",
    "    model = TemporalGCN(\n",
    "        num_features=num_features,\n",
    "        hidden_dim=CONFIG['hidden_dim'],\n",
    "        num_classes=2,\n",
    "        dropout=CONFIG['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG['learning_rate'],\n",
    "        weight_decay=CONFIG['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Class weights from last graph\n",
    "    last_train_graph = train_seq['graphs'][-1]\n",
    "    train_labels = last_train_graph.y[last_train_graph.eval_mask]\n",
    "    class_counts = torch.bincount(train_labels)\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    pbar = tqdm(range(CONFIG['epochs']), desc=f\"K={K}\")\n",
    "    for epoch in pbar:\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_seq['graphs'], optimizer, criterion\n",
    "        )\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            val_metrics = evaluate(model, val_seq['graphs'])\n",
    "            pbar.set_postfix({'loss': f\"{train_loss:.4f}\", 'val_f1': f\"{val_metrics['f1']:.4f}\"})\n",
    "            \n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= CONFIG['patience']:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    train_metrics = evaluate(model, train_seq['graphs'])\n",
    "    val_metrics = evaluate(model, val_seq['graphs'])\n",
    "    test_metrics = evaluate(model, test_seq['graphs'])\n",
    "    \n",
    "    print(f\"\\nTrain: F1={train_metrics['f1']:.4f}, AUC={train_metrics['auc']:.4f}\")\n",
    "    print(f\"Val:   F1={val_metrics['f1']:.4f}, AUC={val_metrics['auc']:.4f}\")\n",
    "    print(f\"Test:  F1={test_metrics['f1']:.4f}, AUC={test_metrics['auc']:.4f}\")\n",
    "    \n",
    "    results[K] = {'train': train_metrics, 'val': val_metrics, 'test': test_metrics}\n",
    "    models[K] = model\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data = []\n",
    "\n",
    "for K in CONFIG['observation_windows']:\n",
    "    metrics = results[K]['test']\n",
    "    comparison_data.append({\n",
    "        'K': K,\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'Precision': f\"{metrics['precision']:.4f}\",\n",
    "        'Recall': f\"{metrics['recall']:.4f}\",\n",
    "        'F1': f\"{metrics['f1']:.4f}\",\n",
    "        'AUC': f\"{metrics['auc']:.4f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F1 Score\n",
    "ax = axes[0]\n",
    "f1_scores = [results[K]['test']['f1'] for K in CONFIG['observation_windows']]\n",
    "ax.plot(CONFIG['observation_windows'], f1_scores, marker='o', linewidth=2, color='red')\n",
    "ax.set_xlabel('Observation Window K', fontsize=12)\n",
    "ax.set_ylabel('F1 Score', fontsize=12)\n",
    "ax.set_title('Temporal GCN: F1 Score vs Observation Window', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "ax = axes[1]\n",
    "auc_scores = [results[K]['test']['auc'] for K in CONFIG['observation_windows']]\n",
    "ax.plot(CONFIG['observation_windows'], auc_scores, marker='o', linewidth=2, color='blue')\n",
    "ax.set_xlabel('Observation Window K', fontsize=12)\n",
    "ax.set_ylabel('AUC', fontsize=12)\n",
    "ax.set_title('Temporal GCN: AUC vs Observation Window', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('../../results', exist_ok=True)\n",
    "os.makedirs('../../models', exist_ok=True)\n",
    "\n",
    "comparison_df.to_csv('../../results/temporal_gcn_results.csv', index=False)\n",
    "print(\"Results saved to ../../results/temporal_gcn_results.csv\")\n",
    "\n",
    "for K, model in models.items():\n",
    "    torch.save(model.state_dict(), f'../../models/temporal_gcn_k{K}.pt')\n",
    "print(f\"Models saved to ../../models/temporal_gcn_k*.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
